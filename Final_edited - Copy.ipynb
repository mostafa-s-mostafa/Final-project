{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NDufLYbI8_3"
      },
      "outputs": [],
      "source": [
        "# Manpulate\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "\n",
        "# Pre-Processing\n",
        "from sklearn.model_selection import train_test_split # train-test-split\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer # detect & handle NaNs\n",
        "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, OneHotEncoder # Ordinal Encoding, Nominal Encoding\n",
        "from category_encoders import BinaryEncoder # Nominal Encoding\n",
        "from imblearn.under_sampling import RandomUnderSampler # undersampling\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE # oversampling\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler # Scaling\n",
        "\n",
        "# Modeling\n",
        "## 1) Pipeline\n",
        "from sklearn.pipeline import Pipeline, make_pipeline # to make pipeline\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer, make_column_selector # apply pipeline to each column\n",
        "\n",
        "## 2) Regression Models\n",
        "from sklearn.linear_model import LinearRegression # if data is small and small_no_features\n",
        "from sklearn.linear_model import SGDRegressor # if data is large: (can have penalty=constrains)\n",
        "from sklearn.preprocessing import PolynomialFeatures # for polynomial regresion (then apply scaling after it)\n",
        "from sklearn.linear_model import Lasso, LassoCV, Ridge, RidgeCV, ElasticNet, ElasticNetCV # Regularization\n",
        "\n",
        "## 2') Classfication Models\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB, CategoricalNB, MultinomialNB\n",
        "from sklearn.svm import LinearSVC, SVC, LinearSVR, SVR\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import VotingClassifier, VotingRegressor # Ensemble (Voting)\n",
        "from sklearn.ensemble import BaggingClassifier, BaggingRegressor, RandomForestClassifier, RandomForestRegressor, ExtraTreesClassifier, ExtraTreesRegressor # Bagging & Pasting\n",
        "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor, GradientBoostingClassifier, GradientBoostingRegressor, HistGradientBoostingClassifier, HistGradientBoostingRegressor # Boosting\n",
        "from sklearn.ensemble import StackingClassifier, StackingRegressor # Stacking\n",
        "\n",
        "## 3) Model Selection (Underfitting vs Overfitting) [bias variance tradeoff => perfect model complexity]\n",
        "from sklearn.model_selection import cross_validate, cross_val_score, cross_val_predict, KFold, StratifiedKFold, GridSearchCV, RandomizedSearchCV # (Train - Valid - Test) + hyperparameters tunning\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV, HalvingRandomSearchCV # if data / features is large\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error # Evaluate Model: r2=> accuracy, L2-norm: if no outliers, L1-norm: if outliers\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, precision_recall_curve, roc_curve, roc_auc_score, auc, confusion_matrix\n",
        "from scipy import stats # Confidence Interval of Accuracy / Loss / Utility\n",
        "import joblib # save model\n",
        "\n",
        "# 4) Dimensionality reduction\n",
        "from sklearn.decomposition import PCA, IncrementalPCA # till 20K features\n",
        "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection # >20k features\n",
        "from sklearn.manifold import LocallyLinearEmbedding, MDS, Isomap, TSNE # Manifold could be better than Projection\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis # for classfication problems (larg distance between diffrent classes)\n",
        "\n",
        "# 5) Clustering\n",
        "from sklearn.cluster import KMeans, MiniBatchKMeans # spherical dataset (n_cluster by (elbow / silhouette_score / silhoutette_samples))\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.cluster import DBSCAN # eps by K-distanceGraph\n",
        "from sklearn.cluster import HDBSCAN # state of art\n",
        "from sklearn.metrics import silhouette_score, silhouette_samples, davies_bouldin_score, calinski_harabasz_score\n",
        "from sklearn.neighbors import NearestNeighbors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50fruJyrI8_4"
      },
      "source": [
        "# Understand data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ps_YJ_EoI8_4"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('diabetic_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "dSEupouhJpko",
        "outputId": "77e6029e-219f-4609-a17a-257bc25dfe1c"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# !ls /content/drive/MyDrive/final project/diabetic_data.csv\n",
        "# file_path = \"/content/drive/MyDrive/final project/diabetic_data.csv\"\n",
        "# df = pd.read_csv(file_path)\n",
        "# df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7Yxq5gyI8_5",
        "outputId": "69266972-b4da-425f-f96f-eaa3ed36f4f6"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "Bv84aCS8I8_5",
        "outputId": "946cf234-fd89-492a-f0f1-517e492282aa"
      },
      "outputs": [],
      "source": [
        "df.replace('?', np.nan, inplace=True)\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ikcdw-T9I8_5"
      },
      "outputs": [],
      "source": [
        "df[['diag_1', 'diag_2', 'diag_3']] = df[['diag_1', 'diag_2', 'diag_3']].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TALAxbfWI8_5",
        "outputId": "59de3721-1ff5-401e-9f7b-61a12d8b2b5d"
      },
      "outputs": [],
      "source": [
        "df.info()\n",
        "# drop weight, max_glu_serum, A1Cresult, encounter_id, patient_nbr, payer_code, medical_specialty\n",
        "# check why num: diag_1, diag_2, diag_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "lRw0RHDoI8_5",
        "outputId": "eb616e90-471e-4ace-d152-0506f4f99b7f"
      },
      "outputs": [],
      "source": [
        "df.describe()\n",
        "# number_inpatient\t21\n",
        "# number_emergency\t76\n",
        "# number_outpatient\t42\n",
        "# num_medications\t81\n",
        "# num_lab_procedures\t132\n",
        "# time_in_hospital  14\n",
        "# gender = 'Unknown/Invalid'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[df['number_diagnoses'] == 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "p4mk4cf1I8_5",
        "outputId": "914acf6e-6263-4d82-95dc-40849e285250"
      },
      "outputs": [],
      "source": [
        "df[df['discharge_disposition_id'] == 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "YoKrehzcI8_5",
        "outputId": "d7673e3b-2e23-4430-d2f8-07aa8f406b08"
      },
      "outputs": [],
      "source": [
        "df[df['time_in_hospital'] >= 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "BeYA7W2MI8_6",
        "outputId": "b88f8ee6-4d9c-4837-f72d-a8c4d6b081a8"
      },
      "outputs": [],
      "source": [
        "df[df['num_lab_procedures'] >= 100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puDhjFW7XUKM"
      },
      "outputs": [],
      "source": [
        "drop_1 = df[df['number_emergency'] >= 20].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhPATv7At_M1"
      },
      "outputs": [],
      "source": [
        "drop_2 = df[df['num_lab_procedures'] >= 100].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QH4_OF0Ct_a7"
      },
      "outputs": [],
      "source": [
        "drop_3 = df[df['num_medications'] > 60].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9I3U3cdI8_6"
      },
      "outputs": [],
      "source": [
        "drop_4 = df[df['gender'] == 'Unknown/Invalid'].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTfVppaR4Yaq"
      },
      "outputs": [],
      "source": [
        "drop_6 = df[df['number_inpatient'] >= 15].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJLbXNlD4YR6",
        "outputId": "288bd400-1040-42d5-9e8b-2d95c6787ca6"
      },
      "outputs": [],
      "source": [
        "drop_7 = df[df['number_outpatient'] > 10].index\n",
        "drop_7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "KXFJeBi2I8_6",
        "outputId": "6f62c811-478f-4bf5-b332-b9cb13b7b424"
      },
      "outputs": [],
      "source": [
        "drop_indices = list(drop_1) + list(drop_2) + list(drop_3) + list(drop_4) + list(drop_6) + list(drop_7)\n",
        "\n",
        "df.drop(drop_indices, axis=0, inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4RbbBilI8_6",
        "outputId": "e606792d-c3cd-4f74-acb6-e8562871e2a2"
      },
      "outputs": [],
      "source": [
        "cat_col = df.select_dtypes(include='O').columns\n",
        "for col in cat_col:\n",
        "    print(f\"the number of Uniques in {col} is {df[col].nunique()}\")\n",
        "    print(f\"the uniques in {col}, is {df[col].unique()}\")\n",
        "    print()\n",
        "    print(\"*\" * 50)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pWWpqvPI8_6"
      },
      "source": [
        "# Extract New Featuers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "iDOg2yGqI8_6",
        "outputId": "32136614-c9ee-4ca6-ec64-c28b0d701fc1"
      },
      "outputs": [],
      "source": [
        "def enhanced_conversion(code):\n",
        "    conversion = {\n",
        "        'numeric_value': 0.0,\n",
        "        'is_V': 0,\n",
        "        'is_E': 0,\n",
        "        'is_numeric': 0\n",
        "    }\n",
        "\n",
        "    if code == 'None':\n",
        "        return conversion\n",
        "\n",
        "    code = str(code)\n",
        "\n",
        "    if code[0].upper() == 'V':\n",
        "        conversion.update({\n",
        "            'is_V': 1,\n",
        "            'numeric_value': float(code[1:]) if code[1:].replace('.','',1).isdigit() else 0.0\n",
        "        })\n",
        "    elif code[0].upper() == 'E':\n",
        "        conversion.update({\n",
        "            'is_E': 1,\n",
        "            'numeric_value': float(code[1:]) if code[1:].replace('.','',1).isdigit() else 0.0\n",
        "        })\n",
        "    else:\n",
        "        try:\n",
        "            conversion.update({\n",
        "                'is_numeric': 1,\n",
        "                'numeric_value': float(code)\n",
        "            })\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    return conversion\n",
        "\n",
        "\n",
        "for col in ['diag_1', 'diag_2', 'diag_3']:\n",
        "    converted = df[col].apply(enhanced_conversion).apply(pd.Series)\n",
        "    df = pd.concat([df, converted.add_prefix(f'{col}_')], axis=1)\n",
        "\n",
        "df[['diag_1_is_V', 'diag_1_is_E', 'diag_1_numeric_value']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkRUNZQpI8_6"
      },
      "outputs": [],
      "source": [
        "def map_numeric_to_range(is_v, is_e, numeric_value):\n",
        "    \"\"\"\n",
        "    Maps numeric ICD-9 codes to ranges.\n",
        "    \"\"\"\n",
        "    if is_v == 1:\n",
        "        if 1 <= numeric_value <= 91:\n",
        "            return \"V01-V91 (Health Status Factors)\"\n",
        "        else:\n",
        "            return \"V_Other\"\n",
        "\n",
        "    elif is_e == 1:\n",
        "        if 800 <= numeric_value <= 999:\n",
        "            return \"E800-E999 (External Causes)\"\n",
        "        else:\n",
        "            return \"E_Other\"\n",
        "\n",
        "    else:\n",
        "        value = int(numeric_value)\n",
        "\n",
        "        if 1 <= value <= 139:\n",
        "            return \"001-139 (Infectious/Parasitic)\"\n",
        "        elif 140 <= value <= 239:\n",
        "            return \"140-239 (Neoplasms)\"\n",
        "        elif 240 <= value <= 279:\n",
        "            return \"240-279 (Endocrine/Metabolic)\"\n",
        "        elif 280 <= value <= 289:\n",
        "            return \"280-289 (Blood Disorders)\"\n",
        "        elif 290 <= value <= 319:\n",
        "            return \"290-319 (Mental Disorders)\"\n",
        "        elif 320 <= value <= 389:\n",
        "            return \"320-389 (Nervous System)\"\n",
        "        elif 390 <= value <= 459:\n",
        "            return \"390-459 (Circulatory)\"\n",
        "        elif 460 <= value <= 519:\n",
        "            return \"460-519 (Respiratory)\"\n",
        "        elif 520 <= value <= 579:\n",
        "            return \"520-579 (Digestive)\"\n",
        "        elif 580 <= value <= 629:\n",
        "            return \"580-629 (Genitourinary)\"\n",
        "        elif 630 <= value <= 679:\n",
        "            return \"630-679 (Pregnancy)\"\n",
        "        elif 680 <= value <= 709:\n",
        "            return \"680-709 (Skin)\"\n",
        "        elif 710 <= value <= 739:\n",
        "            return \"710-739 (Musculoskeletal)\"\n",
        "        elif 740 <= value <= 759:\n",
        "            return \"740-759 (Congenital)\"\n",
        "        elif 760 <= value <= 779:\n",
        "            return \"760-779 (Perinatal)\"\n",
        "        elif 780 <= value <= 799:\n",
        "            return \"780-799 (Symptoms)\"\n",
        "        elif 800 <= value <= 999:\n",
        "            return \"800-999 (Injury/Poisoning)\"\n",
        "        else:\n",
        "            return \"Other\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5v9KQ5HLI8_6",
        "outputId": "f18fd46b-9ae5-49f5-c799-7d2be3d3e5f3"
      },
      "outputs": [],
      "source": [
        "for col in ['diag_1', 'diag_2', 'diag_3']:\n",
        "    df[f'{col}_range'] = df.apply(\n",
        "        lambda row: map_numeric_to_range(\n",
        "            is_v=row[f'{col}_is_V'],\n",
        "            is_e=row[f'{col}_is_E'],\n",
        "            numeric_value=row[f'{col}_numeric_value']\n",
        "        ), axis=1\n",
        "    )\n",
        "\n",
        "df[['diag_1_numeric_value', 'diag_1_range', 'diag_2_numeric_value', 'diag_2_range']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "M6eyu1szO8TE",
        "outputId": "db926fb5-6e9c-4d70-a570-a8c2e01bba6f"
      },
      "outputs": [],
      "source": [
        "keys = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'glipizide', 'glyburide',\n",
        "        'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'insulin', 'glyburide-metformin', 'tolazamide',\n",
        "        'metformin-pioglitazone', 'metformin-rosiglitazone', 'glimepiride-pioglitazone', 'glipizide-metformin',\n",
        "        'troglitazone', 'tolbutamide', 'acetohexamide']\n",
        "\n",
        "df['numchange'] = df[keys].applymap(lambda x: 1 if x not in ['No', 'Steady'] else 0).sum(axis=1)\n",
        "\n",
        "df['numchange'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xDEikczO85s"
      },
      "outputs": [],
      "source": [
        "df['service_utilization'] = df['number_outpatient'] + df['number_emergency'] + df['number_inpatient']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X033bd3XO9ZK"
      },
      "outputs": [],
      "source": [
        "df['is_emergency_admission'] = df['admission_type_id'].apply(lambda x: 1 if x in [1, 2] else 0)\n",
        "df['admission_category'] = df['admission_type_id'].replace({1: 'emergency', 2: 'urgent', 3: 'elective', 4: 'newborn',\n",
        "                                                             5: 'trauma', 6: 'other', 7: 'other', 8: 'other'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OM_VJxYweR8O"
      },
      "outputs": [],
      "source": [
        "df['discharge_to_home'] = df['discharge_disposition_id'].apply(lambda x: 1 if x == 1 else 0)\n",
        "\n",
        "# Grouping discharge categories\n",
        "df['discharge_care_level'] = df['discharge_disposition_id'].replace({\n",
        "    1: 'home', 3: 'rehab', 6: 'transfer', 22: 'hospice', 23: 'hospice',\n",
        "    2: 'short_hospital_stay', 5: 'transfer', 11: 'transfer', 7: 'AMA',\n",
        "    10: 'transfer', 14: 'transfer', 18: 'long_hospital_stay', 8: 'death'\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9m0mVf-FeSex"
      },
      "outputs": [],
      "source": [
        "df['admitted_from_emergency'] = df['admission_source_id'].apply(lambda x: 1 if x == 7 else 0)\n",
        "\n",
        "# Grouping admission sources\n",
        "df['referral_source'] = df['admission_source_id'].replace({\n",
        "    1: 'physician_referral', 2: 'clinic_referral', 3: 'HMO_referral',\n",
        "    4: 'transfer_hospital', 5: 'transfer_healthcare_facility',\n",
        "    6: 'ER', 7: 'ER', 8: 'court_law', 9: 'other'\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tuwnh-M8I8_7"
      },
      "outputs": [],
      "source": [
        "age_mapping = {f'[{i*10}-{(i+1)*10})': i*10+5 for i in range(10)}\n",
        "df['age_midpoint'] = df['age'].map(age_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qV1sf1-t6DtE"
      },
      "outputs": [],
      "source": [
        "df['A1Cresult'] = df['A1Cresult'].replace(np.nan, None)\n",
        "df['max_glu_serum'] = df['max_glu_serum'].replace(np.nan, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6dcD3J85yFm",
        "outputId": "be2fda11-a09b-4fd3-d43b-a96a420334ea"
      },
      "outputs": [],
      "source": [
        "df['A1Cresult'] = df['A1Cresult'].replace('>7', 1)\n",
        "df['A1Cresult'] = df['A1Cresult'].replace('>8', 1)\n",
        "df['A1Cresult'] = df['A1Cresult'].replace('Norm', 0)\n",
        "df['A1Cresult'] = df['A1Cresult'].replace('None', -99)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq-jcWjZ6R_B",
        "outputId": "69f8ff6f-018c-4d85-977c-83ee3ec541c8"
      },
      "outputs": [],
      "source": [
        "df['max_glu_serum'] = df['max_glu_serum'].replace('>200', 1)\n",
        "df['max_glu_serum'] = df['max_glu_serum'].replace('>300', 1)\n",
        "df['max_glu_serum'] = df['max_glu_serum'].replace('Norm', 0)\n",
        "df['max_glu_serum'] = df['max_glu_serum'].replace('None', -99)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmSnfyDdwGNP",
        "outputId": "09f66d8a-b4f9-4781-ea37-1fb9015cf8e2"
      },
      "outputs": [],
      "source": [
        "cat_col = df.select_dtypes(include='O').columns\n",
        "for col in look:\n",
        "    print(f\"the number of Uniques in {col} is {df[col].nunique()}\")\n",
        "    print(f\"the uniques in {col}, is {df[col].unique()}\")\n",
        "    print()\n",
        "    print(\"*\" * 50)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qANyrHDVI8_7"
      },
      "source": [
        "# Uni-variate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I7giHd2DI8_7",
        "outputId": "a9bb557d-90db-4d88-e610-37975dbaf3f5"
      },
      "outputs": [],
      "source": [
        "num_col = df.select_dtypes(include='number').columns\n",
        "fig, axes = plt.subplots(ncols=2, nrows=len(num_col), figsize=(12, len(num_col) * 5))\n",
        "fig.tight_layout(pad=5.0)\n",
        "\n",
        "\n",
        "for i, col in enumerate(num_col):\n",
        "    sns.boxplot(x=df[col], ax=axes[i,0])\n",
        "    axes[i,0].set_title(f\"Box plot of {col}\")\n",
        "\n",
        "    sns.kdeplot(x=df[col], ax=axes[i,1])\n",
        "    axes[i,1].set_title(f\"KDE plot of {col}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5qPJ4vncI8_7",
        "outputId": "d67f2209-334e-4e7e-e394-6fb1274303c1"
      },
      "outputs": [],
      "source": [
        "cat_col = df.select_dtypes(include='object').columns\n",
        "for col in cat_col:\n",
        "    if df[col].nunique() < 7:\n",
        "        print(col)\n",
        "        dff = df.groupby(col).size().reset_index(name=\"count\").sort_values(ascending=False, by=\"count\")\n",
        "        cat_fig = px.pie(dff, names=col, values='count', title=f'distipution of {col}')\n",
        "        cat_fig.show()\n",
        "    elif df[col].nunique() > 7:\n",
        "        print(col)\n",
        "        cat_fig_2 = px.histogram(df, x=col , title=f'distribution of {col}')\n",
        "        cat_fig_2.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnffsP7wI8_7"
      },
      "outputs": [],
      "source": [
        "# Drop unnecessary columns\n",
        "unnecess_col = [\n",
        "    'citoglipton', 'examide',\n",
        "    'diag_1', 'diag_2', 'diag_3', 'age',\n",
        "    'encounter_id', 'patient_nbr', 'weight',\n",
        "    'admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
        "    'payer_code', 'medical_specialty'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gomKvBInC_W-"
      },
      "outputs": [],
      "source": [
        "df.drop(columns=unnecess_col, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "vvg2bVa9I8_7",
        "outputId": "3167b38c-3b50-4121-bc36-822d74fb7c0e"
      },
      "outputs": [],
      "source": [
        "df['readmitted'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9c5fKxe9Kkm"
      },
      "outputs": [],
      "source": [
        "df['readmitted'] = df['readmitted'].map({'NO': 0, '>30': 0, '<30': 1})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iGd5ln0I8_7"
      },
      "source": [
        "# Bi-Variate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XLkGDjalI8_7",
        "outputId": "39dc433d-3ea0-44d6-ad9f-ea44796ef643"
      },
      "outputs": [],
      "source": [
        "num_df_col = df.select_dtypes(include='number')\n",
        "corr_matrix = num_df_col.corr()\n",
        "\n",
        "plt.figure(figsize=(16, 12))\n",
        "sns.heatmap(corr_matrix,\n",
        "            cmap='coolwarm',\n",
        "            annot=True,\n",
        "            fmt=\".2f\",\n",
        "            linewidths=0.5,\n",
        ")\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.countplot(df, x='gender', hue='readmitted')\n",
        "plt.title('distpution between Gender and readmitted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.countplot(df, x='race', hue='readmitted')\n",
        "plt.title('distpution between race and readmitted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.countplot(df, x='diabetesMed', hue='readmitted')\n",
        "plt.title('distpution between diabetesMed and readmitted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.countplot(df, x='age_midpoint', hue='readmitted')\n",
        "plt.title('distpution between age_midpoint and readmitted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zzc0Z9kAI8_7"
      },
      "source": [
        "Multi-Variate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9TVU9-pUI8_7",
        "outputId": "cd445e71-eea6-4d56-901e-bb203a9462e4"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02H6tiF7I8_7"
      },
      "source": [
        "# Clustring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qj01BAXsI8_7"
      },
      "outputs": [],
      "source": [
        "unnecess_clust = ['readmitted']\n",
        "\n",
        "dff = df.drop(columns=unnecess_clust)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsDniMb1h8ll"
      },
      "outputs": [],
      "source": [
        "# One-hot encode categorical features\n",
        "categorical_ohe_cols = [\n",
        "    'race', 'gender', 'change', 'diabetesMed','glipizide-metformin', 'admission_category',\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "# binary encode\n",
        "cat_bin = ['diag_1_range', 'diag_2_range', 'diag_3_range', 'referral_source', 'discharge_care_level']\n",
        "\n",
        "\n",
        "# Numerical features\n",
        "numerical_cols = [\n",
        "    'age_midpoint', 'time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications',\n",
        "    'number_outpatient', 'number_emergency', 'number_inpatient', 'number_diagnoses',\n",
        "    'diag_1_numeric_value', 'diag_2_numeric_value', 'diag_3_numeric_value', 'service_utilization',\n",
        "    'numchange'\n",
        "]\n",
        "\n",
        "# Continuous numerical features (for log transformation)\n",
        "numerical_cols_cont = ['num_lab_procedures', 'num_medications']\n",
        "\n",
        "# Medication features (ordinal encoding)\n",
        "medication_cols = [\n",
        "    'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'glipizide',\n",
        "    'glyburide', 'pioglitazone', 'rosiglitazone', 'insulin', 'acarbose', 'miglitol', 'glyburide-metformin'\n",
        "\n",
        "]\n",
        "\n",
        "cat_order_no = [\n",
        "    'metformin-pioglitazone','metformin-rosiglitazone', 'glimepiride-pioglitazone',\n",
        "    'glipizide-metformin', 'troglitazone', 'tolbutamide', 'acetohexamide'\n",
        "]\n",
        "\n",
        "order_cat_spec = ['tolazamide', 'change', 'diabetesMed']\n",
        "\n",
        "\n",
        "\n",
        "# Define ordinal encoding categories for medications\n",
        "ordinal_mapping_medication = [['No', 'Steady', 'Up', 'Down']] * len(medication_cols)\n",
        "\n",
        "ordinal_map_no_steady = [['No', 'Steady']] * len(cat_order_no)\n",
        "\n",
        "# Define ordinal encoding categories for `order_cat`\n",
        "category_spec = [['No', 'Steady','Up'], ['No', \"Ch\"], ['No', 'Yes']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8M3vI0zEiR-w"
      },
      "outputs": [],
      "source": [
        "# numerical pipeline\n",
        "num_pipe = Pipeline(steps=[\n",
        "    (\"handle_nans\", SimpleImputer(strategy='median')),\n",
        "    (\"scale\", StandardScaler()),\n",
        "])\n",
        "\n",
        "# continuous numerical pipeline\n",
        "num_cont_pipe = Pipeline(steps=[\n",
        "    (\"handle_nans\", SimpleImputer(strategy='median')),\n",
        "    (\"scale\", StandardScaler()),\n",
        "])\n",
        "\n",
        "# one-hot encoding pipeline\n",
        "cat_oht_pipe = Pipeline(steps=[\n",
        "    (\"handle_nans\", SimpleImputer(strategy='most_frequent')),\n",
        "    (\"ohe\", OneHotEncoder(drop='first'))\n",
        "])\n",
        "\n",
        "# binary encoding pipeline\n",
        "cat_bin_pipe = Pipeline(steps=[\n",
        "    (\"handle_nans\", SimpleImputer(strategy='most_frequent')),\n",
        "    (\"Binary\", BinaryEncoder())\n",
        "])\n",
        "\n",
        "# ordinal encoding pipeline\n",
        "cat_order_pipe = Pipeline(steps=[\n",
        "    (\"handle_nans\", SimpleImputer(strategy='most_frequent')),\n",
        "    (\"ordinal\", OrdinalEncoder(categories=category_spec))\n",
        "])\n",
        "\n",
        "# ordinal encoding for `order_cat`\n",
        "cat_order_med_pipe = Pipeline(steps=[\n",
        "    (\"handle_nans\", SimpleImputer(strategy='most_frequent')),\n",
        "    (\"ordinal\", OrdinalEncoder(categories=ordinal_mapping_medication))\n",
        "])\n",
        "\n",
        "cat_order_no_pipe = Pipeline(steps=[\n",
        "    (\"handle_nans\", SimpleImputer(strategy='most_frequent')),\n",
        "    (\"ordinal\", OrdinalEncoder(categories=ordinal_map_no_steady))\n",
        "])\n",
        "\n",
        "processor = ColumnTransformer(transformers=[\n",
        "    ('num_pipe', num_pipe, numerical_cols),\n",
        "    ('num_cont_pipe', num_cont_pipe, numerical_cols_cont),\n",
        "    ('cat_oht_pipe', cat_oht_pipe, categorical_ohe_cols),\n",
        "    ('cat_bin_pipe', cat_bin_pipe, cat_bin),\n",
        "    ('cat_order_pipe', cat_order_pipe, order_cat_spec),\n",
        "    ('cat_order_med_pipe', cat_order_med_pipe, medication_cols),\n",
        "    ('cat_order_no_pipe', cat_order_no_pipe, cat_order_no),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlMmkymWI9AB"
      },
      "outputs": [],
      "source": [
        "dff = dff.dropna(subset=['diag_1_numeric_value', 'diag_2_numeric_value', 'diag_3_numeric_value'])\n",
        "dff = dff.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufJw94IkKKsY",
        "outputId": "e8d63745-7c00-4296-e6a0-d9d2bfa286e5"
      },
      "outputs": [],
      "source": [
        "print(f\"order_cat_spec: {len(order_cat_spec)}, category_spec: {len(category_spec)}\")\n",
        "print(f\"medication_cols: {len(medication_cols)}, ordinal_mapping_medication: {len(ordinal_mapping_medication)}\")\n",
        "print(f\"cat_order_no: {len(cat_order_no)}, ordinal_map_no_steady: {len(ordinal_map_no_steady)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9n-AvDo1I9AB",
        "outputId": "be0f53ba-aa2b-4314-cd41-ff26519f8657"
      },
      "outputs": [],
      "source": [
        "X_processed = processor.fit_transform(dff)\n",
        "X_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEMdevfIH9iM",
        "outputId": "c21d6173-1de1-4e1c-d33d-d133c827b02e"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=0.95)\n",
        "X_pca = pca.fit_transform(X_processed)\n",
        "print(f\"Reduced to {X_pca.shape[1]} dimensions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVQlcUFPI9AB",
        "outputId": "ec2b1f1b-76ca-4cc9-8d07-7e7febe7172c"
      },
      "outputs": [],
      "source": [
        "np.sqrt(X_processed.shape[0] / 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "TLI4-Y0pI9AB",
        "outputId": "ade372a1-bb7c-4c56-9dac-7f73e0d5da98"
      },
      "outputs": [],
      "source": [
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "tsne_results = tsne.fit_transform(X_processed)\n",
        "\n",
        "# Visualize t-SNE\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.scatter(tsne_results[:, 0], tsne_results[:, 1], alpha=0.6)\n",
        "plt.title('t-SNE Visualization of scaled Data')\n",
        "plt.xlabel('t-SNE Component 1')\n",
        "plt.ylabel('t-SNE Component 2')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSd4y5QuI9AB"
      },
      "outputs": [],
      "source": [
        "# # visualization using tnse 3d\n",
        "# tsne = TSNE(n_components=3, perplexity=30, random_state=42)\n",
        "# X_tsne = tsne.fit_transform(X_processed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zIs8wqsI9AB"
      },
      "outputs": [],
      "source": [
        "# tsne_df = pd.DataFrame(X_tsne, columns=['TSNE1', 'TSNE2', 'TSNE3'])\n",
        "# tsne_df['readmitted'] = df['readmitted'].values\n",
        "\n",
        "# # Plot\n",
        "# fig = px.scatter_3d(\n",
        "#     tsne_df,\n",
        "#     x='TSNE1',\n",
        "#     y='TSNE2',\n",
        "#     z='TSNE3',\n",
        "#     color='readmitted',\n",
        "#     title='3D t-SNE Visualization of Patient Readmissions',\n",
        "#     opacity=0.7,\n",
        "#     color_discrete_sequence=px.colors.qualitative.Pastel,\n",
        "#     template='plotly_white'\n",
        "# )\n",
        "# fig.update_layout(margin=dict(l=0, r=0, b=0, t=30))\n",
        "# fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyyuAIbrI9AB"
      },
      "outputs": [],
      "source": [
        "# # visualization using pca 3d\n",
        "# pca = PCA(n_components=3)\n",
        "# X_pca = pca.fit_transform(X_processed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJRYPEEAI9AB"
      },
      "outputs": [],
      "source": [
        "# pca_df = pd.DataFrame(X_pca, columns=['PCA1', 'PCA2', 'PCA3'])\n",
        "# pca_df['readmitted'] = df['readmitted'].values  # Color by target variable\n",
        "\n",
        "# # Plot\n",
        "# fig = px.scatter_3d(\n",
        "#     pca_df,\n",
        "#     x='PCA1',\n",
        "#     y='PCA2',\n",
        "#     z='PCA3',\n",
        "#     color='readmitted',\n",
        "#     title='3D PCA Visualization of Patient Readmissions',\n",
        "#     opacity=0.7,\n",
        "#     color_discrete_sequence=px.colors.qualitative.Vivid,\n",
        "#     template='plotly_dark'\n",
        "# )\n",
        "# fig.update_layout(margin=dict(l=0, r=0, b=0, t=30))\n",
        "# fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJwt6ZVPI9AB"
      },
      "outputs": [],
      "source": [
        "# from sklearn.decomposition import PCA\n",
        "\n",
        "# pca = PCA(n_components=0.95)\n",
        "# X_pca = pca.fit_transform(X_processed)\n",
        "# print(f\"Reduced to {X_pca.shape[1]} dimensions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "FBfSxLOrI9AB",
        "outputId": "f3326832-fb7f-4c3b-fdd3-12927dc75e61"
      },
      "outputs": [],
      "source": [
        "ks = []\n",
        "for k in range(2, 10):\n",
        "    kmeans = KMeans(n_clusters=k, n_init=10)\n",
        "    kmeans.fit(X_processed)\n",
        "    ks.append(kmeans.inertia_)\n",
        "\n",
        "# Plot to find the \"elbow\"\n",
        "plt.plot(range(2, 10), ks)\n",
        "plt.xlabel(\"Number of Clusters\")\n",
        "plt.ylabel(\"WCSS\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "7OkG0GgQI9AC",
        "outputId": "9d8b7abc-2e65-45f8-b552-23a3528741ee"
      },
      "outputs": [],
      "source": [
        "n_clusters = range(2, 12)\n",
        "clustering_models = []\n",
        "silhouette_values = []\n",
        "for k in n_clusters:\n",
        "    kmeans_model = KMeans(n_clusters=k, init='k-means++', n_init=10)\n",
        "    kmeans_model.fit(X_processed)\n",
        "    silhouette_values.append(silhouette_score(X_processed, kmeans_model.labels_))\n",
        "    clustering_models.append(kmeans_model)\n",
        "\n",
        "plt.plot(n_clusters, silhouette_values)\n",
        "plt.xlabel(\"clusters\")\n",
        "plt.ylabel(\"silhouette\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        },
        "id": "fMYe_Q2sI9AC",
        "outputId": "28326a3d-b672-415f-8306-e282ef9c7cfa"
      },
      "outputs": [],
      "source": [
        "# 3) silhouette samples\n",
        "\n",
        "from sklearn.metrics import silhouette_samples\n",
        "from matplotlib.ticker import FixedLocator, FixedFormatter\n",
        "\n",
        "plt.figure(figsize=(11, 9))\n",
        "\n",
        "for k in range(2, 12):\n",
        "    plt.subplot(5, 2, k - 1)\n",
        "\n",
        "    y_pred = clustering_models[k - 2].labels_ # 2, 3, 4\n",
        "    silhouette_coefficients = silhouette_samples(X_processed, y_pred)\n",
        "\n",
        "    padding = len(X_processed) // 30\n",
        "    pos = padding\n",
        "    ticks = []\n",
        "    for i in range(k):\n",
        "        coeffs = silhouette_coefficients[y_pred == i]\n",
        "        coeffs.sort()\n",
        "\n",
        "        color = plt.cm.Spectral(i / k)\n",
        "        plt.fill_betweenx(np.arange(pos, pos + len(coeffs)), 0, coeffs,\n",
        "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
        "        ticks.append(pos + len(coeffs) // 2)\n",
        "        pos += len(coeffs) + padding\n",
        "\n",
        "    plt.gca().yaxis.set_major_locator(FixedLocator(ticks))\n",
        "    plt.gca().yaxis.set_major_formatter(FixedFormatter(range(k)))\n",
        "    if k in (3, 5):\n",
        "        plt.ylabel(\"Cluster\")\n",
        "\n",
        "    if k in (5, 6):\n",
        "        plt.gca().set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
        "        plt.xlabel(\"Silhouette Coefficient\")\n",
        "    else:\n",
        "        plt.tick_params(labelbottom=False)\n",
        "\n",
        "    plt.axvline(x=silhouette_values[k - 2], color=\"red\", linestyle=\"--\")\n",
        "    plt.title(f\"$k={k}$\")\n",
        "\n",
        "# save_fig(\"silhouette_analysis_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "n56BwMFaI9AC",
        "outputId": "c098a734-6118-483b-bfb9-c8c73b4e7dc6"
      },
      "outputs": [],
      "source": [
        "# Step 2: Cluster\n",
        "kmeans = KMeans(n_clusters=3)\n",
        "clusters = kmeans.fit_predict(X_pca)\n",
        "\n",
        "# Step 3: Visualize\n",
        "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='viridis')\n",
        "plt.title('PCA + KMeans Clustering')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "lgIsYDy6I9AC",
        "outputId": "0297b43f-e927-4885-fa13-377b5aa047a1"
      },
      "outputs": [],
      "source": [
        "ks = []\n",
        "for k in range(2, 10):\n",
        "    kmeans = KMeans(n_clusters=k, init='k-means++', n_init=10)\n",
        "    kmeans.fit(X_pca)\n",
        "    ks.append(kmeans.inertia_)\n",
        "\n",
        "# Plot to find the \"elbow\"\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(range(2, 10), ks)\n",
        "plt.xlabel(\"Number of Clusters\")\n",
        "plt.ylabel(\"ks\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "HlmufIn8I9AC",
        "outputId": "1ddc39bd-33a7-466b-9208-d627badf82d5"
      },
      "outputs": [],
      "source": [
        "n_clusters = range(2, 12)\n",
        "clustering_models = []\n",
        "silhouette_values = []\n",
        "for k in n_clusters:\n",
        "    kmeans_model = KMeans(n_clusters=k, init='k-means++', n_init=10)\n",
        "    kmeans_model.fit(X_pca)\n",
        "    silhouette_values.append(silhouette_score(X_pca, kmeans_model.labels_))\n",
        "    clustering_models.append(kmeans_model)\n",
        "\n",
        "plt.plot(n_clusters, silhouette_values)\n",
        "plt.xlabel(\"clusters\")\n",
        "plt.ylabel(\"silhouette\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        },
        "id": "teR-rTi1I9AC",
        "outputId": "1cea3bcb-99a8-43f8-e4a8-2822f94c4214"
      },
      "outputs": [],
      "source": [
        "# 3) silhouette samples\n",
        "\n",
        "from sklearn.metrics import silhouette_samples\n",
        "from matplotlib.ticker import FixedLocator, FixedFormatter\n",
        "\n",
        "plt.figure(figsize=(11, 9))\n",
        "\n",
        "for k in range(2, 12):\n",
        "    plt.subplot(5, 2, k - 1)\n",
        "\n",
        "    y_pred = clustering_models[k - 2].labels_ # 2, 3, 4\n",
        "    silhouette_coefficients = silhouette_samples(X_pca, y_pred)\n",
        "\n",
        "    padding = len(X_pca) // 30\n",
        "    pos = padding\n",
        "    ticks = []\n",
        "    for i in range(k):\n",
        "        coeffs = silhouette_coefficients[y_pred == i]\n",
        "        coeffs.sort()\n",
        "\n",
        "        color = plt.cm.Spectral(i / k)\n",
        "        plt.fill_betweenx(np.arange(pos, pos + len(coeffs)), 0, coeffs,\n",
        "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
        "        ticks.append(pos + len(coeffs) // 2)\n",
        "        pos += len(coeffs) + padding\n",
        "\n",
        "    plt.gca().yaxis.set_major_locator(FixedLocator(ticks))\n",
        "    plt.gca().yaxis.set_major_formatter(FixedFormatter(range(k)))\n",
        "    if k in (3, 5):\n",
        "        plt.ylabel(\"Cluster\")\n",
        "\n",
        "    if k in (5, 6):\n",
        "        plt.gca().set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
        "        plt.xlabel(\"Silhouette Coefficient\")\n",
        "    else:\n",
        "        plt.tick_params(labelbottom=False)\n",
        "\n",
        "    plt.axvline(x=silhouette_values[k - 2], color=\"red\", linestyle=\"--\")\n",
        "    plt.title(f\"$k={k}$\")\n",
        "\n",
        "# save_fig(\"silhouette_analysis_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zGLjcggI9AC"
      },
      "outputs": [],
      "source": [
        "kmeans = KMeans(n_clusters=3, n_init=10)\n",
        "dff['cluster'] = kmeans.fit_predict(X_processed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "XZyuE7x1I9AC",
        "outputId": "538a6081-5089-4059-b481-5bab3b40f174"
      },
      "outputs": [],
      "source": [
        "dff.groupby('cluster').size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkHHFEnzI9AC",
        "outputId": "508a752f-d29e-49e2-c4e3-812e8c4f439d"
      },
      "outputs": [],
      "source": [
        "dff.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Dw8g_uqwI9AC",
        "outputId": "bd5a5856-a876-47d7-b1bb-1834fccdb703"
      },
      "outputs": [],
      "source": [
        "dff[['diag_1_range', 'diag_2_range', 'diag_3_range',]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "424KKX-JI9AC"
      },
      "outputs": [],
      "source": [
        "cluster_profile = dff.groupby('cluster').agg({\n",
        "    'time_in_hospital': 'median',\n",
        "    'num_medications': 'mean',\n",
        "    'age_midpoint': 'median',\n",
        "    'number_inpatient': 'median',\n",
        "    'diag_1_numeric_value':'median',\n",
        "    'diag_2_numeric_value':'median',\n",
        "    'diag_3_numeric_value':'median',\n",
        "    'diag_1_range': lambda x: x.mode()[0],\n",
        "    'diag_2_range': lambda x: x.mode()[0],\n",
        "    'diag_3_range': lambda x: x.mode()[0],\n",
        "    'race': lambda x: x.mode()[0],\n",
        "}).reset_index()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "tBD0J-leI9AC",
        "outputId": "ffdc8048-0659-4e14-81c6-07c1a79f5314"
      },
      "outputs": [],
      "source": [
        "cluster_profile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "9Fjq3tCEI9AD",
        "outputId": "1d253313-20d0-4d8c-fea7-23b047fb54ba"
      },
      "outputs": [],
      "source": [
        "neighbors = NearestNeighbors(n_neighbors=5)\n",
        "neighbors_fit = neighbors.fit(X_pca)\n",
        "distances, _ = neighbors_fit.kneighbors(X_pca)\n",
        "distances = np.sort(distances[:, -1])  # Sort the k-th nearest distances\n",
        "\n",
        "# Plot k-distance graph\n",
        "plt.plot(distances)\n",
        "plt.xlabel(\"Data Points Sorted\")\n",
        "plt.ylabel(\"5th Nearest Neighbor Distance\")\n",
        "plt.title(\"k-NN Distance Plot (Choose Elbow Point for eps)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uM52Bxi-I9AD"
      },
      "outputs": [],
      "source": [
        "# stop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "yCFngLdtI9AD",
        "outputId": "9e7301e1-7d3e-4791-eb44-1aaaeab45eaa"
      },
      "outputs": [],
      "source": [
        "dbscan = DBSCAN(eps=0.05, min_samples=5)\n",
        "labels = dbscan.fit_predict(X_pca)\n",
        "\n",
        "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap=\"viridis\", s=10)\n",
        "plt.title(\"DBSCAN Clustering\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEWcyKFiR9aH",
        "outputId": "7983a143-ebde-48f5-cd33-65954fef4a45"
      },
      "outputs": [],
      "source": [
        "import umap\n",
        "reducer = umap.UMAP(\n",
        "    n_neighbors=10,       # Focus on local structure\n",
        "    min_dist=0.05,        # Tighten clusters\n",
        "    n_components=2,\n",
        "    random_state=42,\n",
        "    metric='euclidean'    # 'cosine' for high dimensional data\n",
        ")\n",
        "\n",
        "X_reduced = reducer.fit_transform(X_processed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sS-Cni_0wptL"
      },
      "outputs": [],
      "source": [
        "# Apply DBSCAN with chosen eps (adjust based on the elbow method)\n",
        "dbscan = DBSCAN(eps=0.05, min_samples=5)\n",
        "labels = dbscan.fit_predict(reducer)\n",
        "\n",
        "# Plot results\n",
        "plt.scatter(reducer[:, 0], reducer[:, 1], c=labels, cmap=\"viridis\", s=10)\n",
        "plt.title(\"DBSCAN Clustering\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "EKF6xPtJI9AD",
        "outputId": "b7884b22-026f-44a1-a5b4-640f391ced7d"
      },
      "outputs": [],
      "source": [
        "import hdbscan\n",
        "\n",
        "hdb = hdbscan.HDBSCAN(\n",
        "    min_cluster_size=50,  # Smaller clusters\n",
        "    min_samples=5,        # Fewer points to form a core point\n",
        "    cluster_selection_epsilon=0.5,  # Merge nearby clusters\n",
        "    alpha=1.0             # Balance cluster stability\n",
        ")\n",
        "labels = hdb.fit_predict(X_reduced)\n",
        "\n",
        "plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=labels, cmap=\"viridis\", s=10)\n",
        "plt.title(\"HDBSCAN Clustering\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaSZsvbNczOS"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Assign noise points to nearest cluster\n",
        "noise_mask = labels == -1\n",
        "if sum(noise_mask) > 0:\n",
        "    nn = NearestNeighbors(n_neighbors=1).fit(X_reduced[~noise_mask])\n",
        "    _, indices = nn.kneighbors(X_reduced[noise_mask])\n",
        "    labels[noise_mask] = labels[~noise_mask][indices.flatten()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "VOcqaW82c1hr",
        "outputId": "ebcb89d0-347e-4c38-981b-b09b4c6525a0"
      },
      "outputs": [],
      "source": [
        "plt.scatter(\n",
        "    X_reduced[:, 0], X_reduced[:, 1],\n",
        "    c=labels, cmap=\"viridis\", s=10,\n",
        "    edgecolor='none', alpha=0.8\n",
        ")\n",
        "plt.title(\"HDBSCAN Clustering (Noise Highlighted)\")\n",
        "plt.xlabel(\"UMAP 1\")\n",
        "plt.ylabel(\"UMAP 2\")\n",
        "plt.colorbar(label=\"Cluster Label\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1zo3PEBQwgp",
        "outputId": "b3a1a441-4513-42f4-ef7c-db1075afe8d4"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
        "\n",
        "mask = labels != -1\n",
        "if np.unique(labels[mask]).size > 1:  # Ensure at least two clusters exist\n",
        "    silhouette = silhouette_score(X_reduced[mask], labels[mask])\n",
        "    davies_bouldin = davies_bouldin_score(X_reduced[mask], labels[mask])\n",
        "    calinski_harabasz = calinski_harabasz_score(X_reduced[mask], labels[mask])\n",
        "\n",
        "    print(f\"Silhouette Score (higher is better): {silhouette:.2f}\")\n",
        "    print(f\"Davies-Bouldin Score (lower is better): {davies_bouldin:.2f}\")\n",
        "    print(f\"Calinski-Harabasz Score (higher is better): {calinski_harabasz:.2f}\")\n",
        "else:\n",
        "    print(\"Not enough clusters detected for meaningful evaluation.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkrCgQEdansW",
        "outputId": "b54537da-e5c0-4d3d-8130-48b92e3fbe46"
      },
      "outputs": [],
      "source": [
        "df_with_clusters = df.copy()\n",
        "df_with_clusters[\"Cluster\"] = labels\n",
        "\n",
        "# Analyze the number of points in each cluster\n",
        "cluster_counts = df_with_clusters[\"Cluster\"].value_counts().sort_index()\n",
        "print(cluster_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C850DGAmncnB",
        "outputId": "7fb57270-8e6f-4ef5-ed5c-4c8620f09f55"
      },
      "outputs": [],
      "source": [
        "noise_points = df_with_clusters[df_with_clusters[\"Cluster\"] == -1]\n",
        "noise_points.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "GkX5Inmengty",
        "outputId": "eed92da5-5740-4554-a59d-4d917dcb6e75"
      },
      "outputs": [],
      "source": [
        "cluster_0 = df_with_clusters[df_with_clusters[\"Cluster\"] == 0]\n",
        "cluster_0.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "wNgsG9ktnwdR",
        "outputId": "f2db0542-b119-4482-95be-1aebc86daba6"
      },
      "outputs": [],
      "source": [
        "# Plot histogram of cluster counts\n",
        "plt.bar(cluster_counts.index, cluster_counts.values, color=\"skyblue\")\n",
        "plt.xlabel(\"Cluster\")\n",
        "plt.ylabel(\"Number of Points\")\n",
        "plt.title(\"Cluster Distribution\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "R2dEIOxwbLzS",
        "outputId": "2d87124b-c7fd-4ef0-a478-a7a06b632c8b"
      },
      "outputs": [],
      "source": [
        "cluster_profile = df_with_clusters.groupby('Cluster').agg({\n",
        "    'time_in_hospital': 'median',\n",
        "    'num_medications': 'mean',\n",
        "    'age_midpoint': 'median',\n",
        "    'number_inpatient': 'median',\n",
        "    'diag_1_numeric_value':'median',\n",
        "    'diag_2_numeric_value':'median',\n",
        "    'diag_3_numeric_value':'median',\n",
        "    'diag_1_range': lambda x: x.mode()[0],\n",
        "    'diag_2_range': lambda x: x.mode()[0],\n",
        "    'diag_3_range': lambda x: x.mode()[0],\n",
        "    'race': lambda x: x.mode()[0],\n",
        "    'readmitted': lambda x: x.mode()[0],\n",
        "}).reset_index()\n",
        "cluster_profile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCJe3na92HgW",
        "outputId": "9a5a7074-65f9-456e-a4a7-3043d9266d82"
      },
      "outputs": [],
      "source": [
        "print(cluster_profile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bMUS8yZLayu_",
        "outputId": "76ed6ad7-ddb9-417f-8b46-0c50d4b61cd1"
      },
      "outputs": [],
      "source": [
        "numeric_features = df_with_clusters.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "for feature in numeric_features:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    for cluster in sorted(df_with_clusters[\"Cluster\"].unique()):\n",
        "        cluster_data = df_with_clusters[df_with_clusters[\"Cluster\"] == cluster][feature]\n",
        "        sns.histplot(\n",
        "            cluster_data, bins=20, kde=True, label=f\"Cluster {cluster}\", alpha=0.5\n",
        "        )\n",
        "\n",
        "    plt.xlabel(feature, fontsize=12)\n",
        "    plt.ylabel(\"Density\", fontsize=12)\n",
        "    plt.title(f\"Feature Distribution by Cluster: {feature}\", fontsize=14)\n",
        "    plt.legend(title=\"Cluster\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Analyze noise points (if they exist)\n",
        "if 'Cluster' in df_with_clusters.columns and -1 in df_with_clusters[\"Cluster\"].values:\n",
        "    noise_points = df_with_clusters[df_with_clusters[\"Cluster\"] == -1]\n",
        "    print(\"Noise point summary statistics:\\n\", noise_points.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vo84xqA_N2qc"
      },
      "outputs": [],
      "source": [
        "# stop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "eb99qMrQxKse",
        "outputId": "a2c0d7c0-440d-41db-e1ea-64e5183ceb4d"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# # Save DataFrame\n",
        "# output_filename = \"clustered_data.csv\"\n",
        "# df_with_clusters.to_csv(output_filename, index=False)\n",
        "\n",
        "# # Download the file\n",
        "# files.download(output_filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqJLLEMqjv_O",
        "outputId": "55deb40a-c373-4039-f971-47f606ab23d5"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# !ls /content/drive/MyDrive/final project/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "z7eierFDy-Tv",
        "outputId": "eb4f599c-4d52-4ab9-a164-ee759056334f"
      },
      "outputs": [],
      "source": [
        "# file_path_2 = \"/content/drive/MyDrive/final project/clustered_data.csv\"\n",
        "# df_with_clusters = pd.read_csv(file_path_2)\n",
        "# df_with_clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_with_clusters = pd.read_csv('clustered_data.csv')\n",
        "df_with_clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cat_col = df_with_clusters.select_dtypes(include='O').columns\n",
        "for col in cat_col:\n",
        "    print(f\"the number of Uniques in {col} is {df_with_clusters[col].nunique()}\")\n",
        "    print(f\"the uniques in {col}, is {df_with_clusters[col].unique()}\")\n",
        "    print()\n",
        "    print(\"*\" * 50)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "df_with_clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_with_clusters[['diag_2_numeric_value', 'diag_3_numeric_value', 'diag_1_numeric_value']].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7xkmnr3I9AD"
      },
      "source": [
        "# Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3pGo5pbI9AD"
      },
      "source": [
        "Pre-Processing\n",
        "* a) Detect & Handle Duplicates\n",
        "* b) train_test_split\n",
        "* c) Detect & Handle NaNs\n",
        "* d) Detect & Handle Outliers\n",
        "* e) Encoding: (Ordinal:[OrdinalEncoder, LabelEncoder] - Nominal: [< 7 uniques(OneHotEncoding), > 7 uniques (BinaryEncoder)])\n",
        "* f) Imbalanced: X_train_resampled\n",
        "* g) Scaling: StandardScaler, MinMaxScaler, RobustScaler: X_train_resampled_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xq5tVFtN0kab",
        "outputId": "50004713-2e3d-4876-a746-8fe57d244706"
      },
      "outputs": [],
      "source": [
        "df_with_clusters.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qR57vF2I9AD"
      },
      "source": [
        "a) Detect & Handle Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLJWSYLhI9AD",
        "outputId": "4d7f0add-34c0-421b-98c3-77a5178ba6ed"
      },
      "outputs": [],
      "source": [
        "df_with_clusters.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-md4NdKqI9AD"
      },
      "outputs": [],
      "source": [
        "df_with_clusters.drop_duplicates(inplace = True)\n",
        "df_with_clusters.reset_index(inplace= True, drop= True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri3wX_3mI9AD"
      },
      "source": [
        "b) train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixGIWetsI9AD"
      },
      "outputs": [],
      "source": [
        "X = df_with_clusters.drop('readmitted', axis=1)\n",
        "y = df_with_clusters['readmitted']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "zhhncv8li3L5",
        "outputId": "2bcf8487-c75c-429a-a2e3-fc3af7957421"
      },
      "outputs": [],
      "source": [
        "y.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lVSQbMjI9AD"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSFnTfE_I9AD"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class loge_transformer(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.n_featuers_in_ = X.shape[1]\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        assert X.shape[1] == self.n_featuers_in_\n",
        "        return np.log(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFUPGGVWhXKg"
      },
      "outputs": [],
      "source": [
        "# One-hot encode categorical features\n",
        "categorical_ohe_cols = [\n",
        "    'race', 'gender', 'change', 'diabetesMed','glipizide-metformin', 'admission_category',\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "# binary encode\n",
        "cat_bin = ['diag_1_range', 'diag_2_range', 'diag_3_range', 'referral_source', 'discharge_care_level']\n",
        "\n",
        "\n",
        "# Numerical features\n",
        "numerical_cols = [\n",
        "    'age_midpoint', 'time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications',\n",
        "    'number_outpatient', 'number_emergency', 'number_inpatient', 'number_diagnoses',\n",
        "    'diag_1_numeric_value', 'diag_2_numeric_value', 'diag_3_numeric_value', 'service_utilization',\n",
        "    'numchange'\n",
        "]\n",
        "\n",
        "# Continuous numerical features (for log transformation)\n",
        "numerical_cols_cont = ['num_lab_procedures', 'num_medications']\n",
        "\n",
        "# Medication features (ordinal encoding)\n",
        "medication_cols = [\n",
        "    'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'glipizide',\n",
        "    'glyburide', 'pioglitazone', 'rosiglitazone', 'insulin', 'acarbose', 'miglitol', 'glyburide-metformin'\n",
        "\n",
        "]\n",
        "\n",
        "cat_order_no = [\n",
        "    'metformin-pioglitazone','metformin-rosiglitazone', 'glimepiride-pioglitazone',\n",
        "    'glipizide-metformin', 'troglitazone', 'tolbutamide', 'acetohexamide'\n",
        "]\n",
        "\n",
        "order_cat_spec = ['tolazamide', 'change', 'diabetesMed']\n",
        "\n",
        "\n",
        "\n",
        "# Define ordinal encoding categories for medications\n",
        "ordinal_mapping_medication = [['No', 'Steady', 'Up', 'Down']] * len(medication_cols)\n",
        "\n",
        "ordinal_map_no_steady = [['No', 'Steady']] * len(cat_order_no)\n",
        "\n",
        "# Define ordinal encoding categories for `order_cat`\n",
        "category_spec = [['No', 'Steady','Up'], ['No', \"Ch\"], ['No', 'Yes']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RT-JfNI4hXn_"
      },
      "outputs": [],
      "source": [
        "# numerical pipeline\n",
        "num_pipe = Pipeline(steps=[\n",
        "    (\"handle_nans\", SimpleImputer(strategy='median')),\n",
        "    (\"scale\", StandardScaler()),\n",
        "])\n",
        "\n",
        "# continuous numerical pipeline\n",
        "num_cont_pipe = Pipeline(steps=[\n",
        "    (\"handle_nans\", SimpleImputer(strategy='median')),\n",
        "    (\"scale\", StandardScaler()),\n",
        "])\n",
        "\n",
        "# one-hot encoding pipeline\n",
        "cat_oht_pipe = Pipeline(steps=[\n",
        "    (\"handle_nans\", SimpleImputer(strategy='most_frequent')),\n",
        "    (\"ohe\", OneHotEncoder(drop='first'))\n",
        "])\n",
        "\n",
        "# binary encoding pipeline\n",
        "cat_bin_pipe = Pipeline(steps=[\n",
        "    (\"handle_nans\", SimpleImputer(strategy='most_frequent')),\n",
        "    (\"Binary\", BinaryEncoder())\n",
        "])\n",
        "\n",
        "# ordinal encoding pipeline\n",
        "cat_order_pipe = Pipeline(steps=[\n",
        "    (\"handle_nans\", SimpleImputer(strategy='most_frequent')),\n",
        "    (\"ordinal\", OrdinalEncoder(categories=category_spec))\n",
        "])\n",
        "\n",
        "# ordinal encoding for `order_cat`\n",
        "cat_order_med_pipe = Pipeline(steps=[\n",
        "    (\"handle_nans\", SimpleImputer(strategy='most_frequent')),\n",
        "    (\"ordinal\", OrdinalEncoder(categories=ordinal_mapping_medication))\n",
        "])\n",
        "\n",
        "cat_order_no_pipe = Pipeline(steps=[\n",
        "    (\"handle_nans\", SimpleImputer(strategy='most_frequent')),\n",
        "    (\"ordinal\", OrdinalEncoder(categories=ordinal_map_no_steady))\n",
        "])\n",
        "\n",
        "processor = ColumnTransformer(transformers=[\n",
        "    ('num_pipe', num_pipe, numerical_cols),\n",
        "    ('num_cont_pipe', num_cont_pipe, numerical_cols_cont),\n",
        "    ('cat_oht_pipe', cat_oht_pipe, categorical_ohe_cols),\n",
        "    ('cat_bin_pipe', cat_bin_pipe, cat_bin),\n",
        "    ('cat_order_pipe', cat_order_pipe, order_cat_spec),\n",
        "    ('cat_order_med_pipe', cat_order_med_pipe, medication_cols),\n",
        "    ('cat_order_no_pipe', cat_order_no_pipe, cat_order_no),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Saav_vHI9AD",
        "outputId": "e6d3e132-8295-45ab-8289-d6f7b6ba6baa"
      },
      "outputs": [],
      "source": [
        "X_train_preprocessor = processor.fit_transform(X_train)\n",
        "X_test_preprocessor = processor.transform(X_test)\n",
        "X_test_preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "7M7wKvBWI9AE",
        "outputId": "386a8381-aaab-45c8-88de-0e46f765eec2"
      },
      "outputs": [],
      "source": [
        "y_train_preprocessor = y_train\n",
        "y_test_preprocessor = y_test\n",
        "sns.boxplot(y_train_preprocessor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(len(X_test), len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcqW_pxEI9AE"
      },
      "outputs": [],
      "source": [
        "smote_pipeline = ImbPipeline([\n",
        "    ('preprocessor', processor),\n",
        "    ('smote', SMOTE(sampling_strategy=0.5, random_state=42))\n",
        "])\n",
        "X_train_resampled, y_train_resampled = smote_pipeline.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_real, X_val, y_train_real, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, shuffle=True, stratify=y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(y_train_resampled.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_3PoLfiI9AE"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc-Iw1NJA0CH"
      },
      "source": [
        "## SimpleModel (ex: lin_reg, liner_svm, knn, NB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "xMtXXyLII9AE",
        "outputId": "cdf0bea6-f369-4098-b2b8-de09a763589e"
      },
      "outputs": [],
      "source": [
        "log_reg = LogisticRegression(C=1, random_state=42, max_iter=1000, class_weight='balanced')\n",
        "log_reg.fit(X_train_resampled, y_train_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rvo1TX2uI9AE",
        "outputId": "73258661-8219-4751-d267-63e518ba2a53"
      },
      "outputs": [],
      "source": [
        "y_train_pred = log_reg.predict(X_train_resampled)\n",
        "valid_acc = cross_val_score(log_reg, X_train_resampled, y_train_resampled, cv=5)\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train_resampled, y_pred=y_train_pred)}\")\n",
        "print(f\"Validation Accuracy: {valid_acc.mean()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIAj-t4Wu0AB",
        "outputId": "afde33ec-d74b-4cf8-a187-191a25b0814f"
      },
      "outputs": [],
      "source": [
        "y_vald_log_pred = cross_val_predict(log_reg, X_train_resampled, y_train_resampled, cv=5)\n",
        "confusion_matrix(y_train_resampled, y_vald_log_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qvFpHhUv7cM",
        "outputId": "e25dbcff-c95c-40dc-c42d-1c1d83a6c0dd"
      },
      "outputs": [],
      "source": [
        "percison_score_log = precision_score(y_true=y_train_resampled, y_pred=y_vald_log_pred)\n",
        "recall_score_log = recall_score(y_true=y_train_resampled, y_pred=y_vald_log_pred)\n",
        "f1_score_log = f1_score(y_true=y_train_resampled, y_pred=y_vald_log_pred)\n",
        "print(f\"Precision Score: {percison_score_log}\")\n",
        "print(f\"Recall Score: {recall_score}\")\n",
        "print(f\"F1 Score: {f1_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0aUAWnyq_vz",
        "outputId": "cfa16786-57ab-48bf-ec29-e8d2f05d005b"
      },
      "outputs": [],
      "source": [
        "Lin_svc_mod = LinearSVC(random_state=42, C=10, max_iter=10000)\n",
        "\n",
        "# Standard K-Fold CV (Not ideal for imbalanced data)\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "kf_scores = cross_val_score(Lin_svc_mod, X_train_resampled, y_train_resampled, cv=kf, scoring='accuracy')\n",
        "\n",
        "# Stratified K-Fold CV (Better for imbalanced data)\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "skf_scores = cross_val_score(Lin_svc_mod, X_train_resampled, y_train_resampled, cv=skf, scoring='accuracy')\n",
        "\n",
        "print(f\"K-Fold CV Scores: {kf_scores}, Mean: {kf_scores.mean():.4f}\")\n",
        "print(f\"Stratified K-Fold CV Scores: {skf_scores}, Mean: {skf_scores.mean():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gDSCemTt0XO",
        "outputId": "da38e5fb-3e5c-46a0-bf93-47af0d0d302b"
      },
      "outputs": [],
      "source": [
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train_resampled, y_train_resampled)\n",
        "y_nb_pred = nb_model.predict(X_train_resampled)\n",
        "\n",
        "\n",
        "valid_nb_acc = cross_val_score(nb_model, X_train_resampled, y_train_resampled, cv=5)\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train_resampled, y_pred=y_nb_pred)}\")\n",
        "print(f\"Validation Accuracy: {valid_nb_acc.mean()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OC65ZGujpcZc"
      },
      "outputs": [],
      "source": [
        "svm_model = SVC(C=1, kernel='linear', random_state=42)\n",
        "\n",
        "svm_model.fit(X_train_resampled, y_train_resampled)\n",
        "y_svm_pred = svm_model.predict(X_train_resampled)\n",
        "\n",
        "svm_train_acc = accuracy_score(y_train_resampled, y_svm_pred)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "valid_svm_acc = cross_val_score(svm_model, X_train_resampled, y_train_resampled, cv=skf, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "print(f\"Train Accuracy: {svm_train_acc:.4f}\")\n",
        "print(f\"Validation Accuracy: {valid_svm_acc.mean():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOB1mBmhIXli"
      },
      "outputs": [],
      "source": [
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "sgd_model = SGDClassifier(loss=\"hinge\", alpha=1e-4, max_iter=1000, random_state=42 ,class_weight='balanced', n_jobs=-1)\n",
        "\n",
        "skf_sgd_scores = cross_val_score(sgd_model, X_train_resampled, y_train_resampled, cv=skf, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "print(f\"Optimized Stratified K-Fold CV Scores: {skf_sgd_scores}, Mean: {skf_sgd_scores.mean():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNr5wY6rwBKn"
      },
      "outputs": [],
      "source": [
        "# poly svc\n",
        "poly_svm = SVC(C=1, kernel='poly', degree=2, random_state=42, class_weight='balanced')\n",
        "poly_svm.fit(X_train_resampled, y_train_resampled)\n",
        "poly_svm_pred = poly_svm.predict(X_train_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-YfaW_4x3Lw",
        "outputId": "b75b51f6-b4aa-4d73-b4fa-a0512afb4153"
      },
      "outputs": [],
      "source": [
        "valid_acc = cross_val_score(poly_svm, X_train_resampled, y_train_resampled, cv=3)\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train_resampled, y_pred=poly_svm_pred)}\")\n",
        "print(f\"Validation Accuracy: {valid_acc.mean()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdW18ExZF6g1"
      },
      "outputs": [],
      "source": [
        "knn_model = KNeighborsClassifier(n_neighbors=10, weights='uniform')\n",
        "\n",
        "knn_model.fit(X_train_resampled, y_train_resampled)\n",
        "y_knn_pred = knn_model.predict(X_train_resampled)\n",
        "valid_knn_acc = cross_val_score(knn_model, X_train_resampled, y_train_resampled, cv=5)\n",
        "\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train_resampled, y_pred=y_knn_pred)}\")\n",
        "print(f\"Validation Accuracy: {valid_knn_acc.mean()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQWiqKy_BfsM"
      },
      "source": [
        "## Complex Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puD8CTzzSTnr"
      },
      "outputs": [],
      "source": [
        "svm_rbf_model = SVC(C=10, kernel='rbf', random_state=42, gamma=1, probability=True)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "skf_scores = cross_val_score(svm_rbf_model, X_train_resampled, y_train_resampled, cv=skf, scoring='accuracy')\n",
        "\n",
        "svm_rbf_model.fit(X_train_resampled, y_train_resampled)\n",
        "y_svm_rbf_pred = svm_rbf_model.predict(X_train_resampled)\n",
        "\n",
        "print(f\"train acc {accuracy_score(y_train_resampled, y_pred=y_svm_rbf_pred)}\")\n",
        "print(f\"Stratified K-Fold CV Scores: {skf_scores}, Mean: {skf_scores.mean():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCPynG1r9FRa"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'C': [1, 5, 10, 20, 50],\n",
        "    'gamma': ['scale', 0.1, 1, 5]\n",
        "}\n",
        "\n",
        "svm_rbf_model = SVC(kernel='rbf', random_state=42, probability=True)\n",
        "\n",
        "grid_search = GridSearchCV(svm_rbf_model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "best_svm = grid_search.best_estimator_\n",
        "print(f\"Train Accuracy: {accuracy_score(y_train_resampled, best_svm.predict(X_train_resampled))}\")\n",
        "print(f\"Validation Accuracy (CV): {grid_search.best_score_:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1RM5Jxvdt5Y",
        "outputId": "9109a3aa-0240-474f-dfa7-d90b4380779a"
      },
      "outputs": [],
      "source": [
        "dt_model = DecisionTreeClassifier(random_state=42, max_depth=5, min_samples_split=10, min_samples_leaf=5)\n",
        "dt_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Predict on test set\n",
        "y_dt_pred = dt_model.predict(X_train_resampled)\n",
        "valid_dt_acc = cross_val_score(dt_model, X_train_resampled, y_train_resampled, cv=5)\n",
        "\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train_resampled, y_pred=y_dt_pred)}\")\n",
        "print(f\"Validation Accuracy: {valid_dt_acc.mean()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYIQhIxFd8Qd",
        "outputId": "4dee47bf-24d4-433c-c466-15171b4cc6d6"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'max_depth': [3, 5, 10],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 5, 10]\n",
        "}\n",
        "grid_dt_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
        "grid_dt_search.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "print(\"Best parameters:\", grid_dt_search.best_params_)\n",
        "\n",
        "best_dt = grid_dt_search.best_estimator_\n",
        "print(f\"Train Accuracy: {accuracy_score(y_train_resampled, best_dt.predict(X_train_resampled))}\")\n",
        "print(f\"Validation Accuracy (CV): {grid_dt_search.best_score_:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByYHZUIsAqTF"
      },
      "source": [
        "## Bagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Re9kks0AmKm",
        "outputId": "24c344b4-56e1-4629-bead-67c637418b76"
      },
      "outputs": [],
      "source": [
        "rfc_model_1 = RandomForestClassifier(n_estimators=1000, random_state=42, max_depth=7, min_samples_split=2, min_samples_leaf=2)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "valid_rfc_1_acc = cross_val_score(rfc_model_1, X_train_resampled, y_train_resampled, cv=skf)\n",
        "\n",
        "rfc_model_1.fit(X_train_resampled, y_train_resampled)\n",
        "y_rfc_model_1_pred = rfc_model_1.predict(X_train_resampled)\n",
        "\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train_resampled, y_pred=y_rfc_model_1_pred)}\")\n",
        "print(f\"Validation Accuracy: {valid_rfc_1_acc.mean()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rp89i6SmRbXd",
        "outputId": "56c63c00-d8cf-4814-b21a-e324ada46b54"
      },
      "outputs": [],
      "source": [
        "rfc_model = RandomForestClassifier(\n",
        "    n_estimators=1200,\n",
        "    max_depth=10,\n",
        "    min_samples_split=4,\n",
        "    min_samples_leaf=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "valid_rfc_acc = cross_val_score(rfc_model, X_train_resampled, y_train_resampled, cv=skf)\n",
        "\n",
        "rfc_model.fit(X_train_resampled, y_train_resampled)\n",
        "y_rfc_model_pred = rfc_model.predict(X_train_resampled)\n",
        "\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train_resampled, y_pred=y_rfc_model_pred)}\")\n",
        "print(f\"Validation Accuracy: {valid_rfc_acc.mean()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_vald_rfc_pred = cross_val_predict(rfc_model, X_train_resampled, y_train_resampled, cv=skf)\n",
        "confusion_matrix(y_train_resampled, y_vald_rfc_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "percison_rfc_score = precision_score(y_true=y_train_resampled, y_pred=y_vald_rfc_pred)\n",
        "recall_rfc_score = recall_score(y_true=y_train_resampled, y_pred=y_vald_rfc_pred)\n",
        "f1_rfc_score = f1_score(y_true=y_train_resampled, y_pred=y_vald_rfc_pred)\n",
        "print(f\"Precision Score: {percison_rfc_score}\")\n",
        "print(f\"Recall Score: {recall_rfc_score}\")\n",
        "print(f\"F1 Score: {f1_rfc_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTWrKxj99Qci",
        "outputId": "f4cfba50-7ed3-4ba0-e39f-aaaa0198f4a0"
      },
      "outputs": [],
      "source": [
        "param_dist = {\n",
        "    'n_estimators': [100, 300, 500],\n",
        "    'max_depth': [10, 20, 30, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Randomized Search\n",
        "random_search = RandomizedSearchCV(rf, param_dist, cv=5, scoring='roc_auc', n_jobs=-1, n_iter=10, random_state=42)\n",
        "random_search.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "print(\"Best parameters:\", random_search.best_params_)\n",
        "\n",
        "best_rf = random_search.best_estimator_\n",
        "print(f\"Train Accuracy: {accuracy_score(y_train_resampled, best_rf.predict(X_train_resampled))}\")\n",
        "print(f\"Validation Accuracy (CV): {random_search.best_score_:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rfc_model_4 = RandomForestClassifier(n_estimators=500, random_state=42, max_depth=30, min_samples_split=2, min_samples_leaf=4, bootstrap=False)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "valid_rfc_4_acc = cross_val_score(rfc_model_4, X_train_resampled, y_train_resampled, cv=skf)\n",
        "\n",
        "rfc_model_4.fit(X_train_resampled, y_train_resampled)\n",
        "y_rfc_model_4_pred = rfc_model_4.predict(X_train_resampled)\n",
        "\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train_resampled, y_pred=y_rfc_model_4_pred)}\")\n",
        "print(f\"Validation Accuracy: {valid_rfc_4_acc.mean()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rfc_model_3 = RandomForestClassifier(n_estimators=500, random_state=42, max_depth=20, min_samples_split=2, min_samples_leaf=4, bootstrap=False)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "valid_rfc_3_acc = cross_val_score(rfc_model_3, X_train_resampled, y_train_resampled, cv=skf)\n",
        "\n",
        "rfc_model_3.fit(X_train_resampled, y_train_resampled)\n",
        "y_rfc_model_3_pred = rfc_model_3.predict(X_train_resampled)\n",
        "\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train_resampled, y_pred=y_rfc_model_3_pred)}\")\n",
        "print(f\"Validation Accuracy: {valid_rfc_3_acc.mean()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rfc_model_5 = RandomForestClassifier(n_estimators=400, random_state=42, max_depth=15, min_samples_split=2, min_samples_leaf=4, bootstrap=False)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "valid_rfc_5_acc = cross_val_score(rfc_model_5, X_train_resampled, y_train_resampled, cv=skf)\n",
        "\n",
        "rfc_model_5.fit(X_train_resampled, y_train_resampled)\n",
        "y_rfc_model_5_pred = rfc_model_5.predict(X_train_resampled)\n",
        "\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train_resampled, y_pred=y_rfc_model_5_pred)}\")\n",
        "print(f\"Validation Accuracy: {valid_rfc_5_acc.mean()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_vald_rfc5_pred = cross_val_predict(rfc_model_5, X_train_resampled, y_train_resampled, cv=skf)\n",
        "confusion_matrix(y_train_resampled, y_vald_rfc5_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "percison_rfc5_score = precision_score(y_true=y_train_resampled, y_pred=y_vald_rfc5_pred)\n",
        "recall_rfc5_score = recall_score(y_true=y_train_resampled, y_pred=y_vald_rfc5_pred)\n",
        "f1_rfc5_score = f1_score(y_true=y_train_resampled, y_pred=y_vald_rfc5_pred)\n",
        "print(f\"Precision Score: {percison_rfc5_score}\")\n",
        "print(f\"Recall Score: {recall_rfc5_score}\")\n",
        "print(f\"F1 Score: {f1_rfc5_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_dist = {\n",
        "    'rfc__n_estimators': [100, 300, 500],\n",
        "    'rfc__max_depth': [10, 20, 30, None],\n",
        "    'rfc__min_samples_split': [2, 5, 10],\n",
        "    'rfc__min_samples_leaf': [1, 2, 4],\n",
        "    'rfc__bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "\n",
        "train_pipeline = ImbPipeline([\n",
        "    ('preprocessor', processor),\n",
        "    ('smote', SMOTE(sampling_strategy=0.5, random_state=42)),\n",
        "    ('rfc', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "grid_rfc_search = GridSearchCV(train_pipeline, param_dist, cv=skf, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "valid_accuracy_score = []\n",
        "valid_f1_score = []\n",
        "valid_precision_score = []\n",
        "valid_recall_score = []\n",
        "\n",
        "skfolds = StratifiedKFold(n_splits=5)\n",
        "i = 1\n",
        "for train_indx, valid_indx in skfolds.split(X_train, y_train): # 150 Model\n",
        "    print(f\"At fold {i}\")\n",
        "    # print(y_train.iloc[train_indx].value_counts(normalize=True))\n",
        "    # print(y_train.iloc[valid_indx].value_counts(normalize=True))\n",
        "    # print()\n",
        "\n",
        "    grid_rfc_search.fit(X_train.iloc[train_indx], y_train.iloc[train_indx]) # 30 Model\n",
        "    best_svm_clf_model = grid_rfc_search.best_estimator_\n",
        "    y_valid_pred = grid_rfc_search.predict(X_train.iloc[valid_indx])\n",
        "\n",
        "    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))\n",
        "    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))\n",
        "    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))\n",
        "    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))\n",
        "\n",
        "    i += 1\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Average Valid Accuracy: {np.mean(valid_accuracy_score)}\") # Valid accuracy\n",
        "print(f\"Average Valid F1 Score: {np.mean(valid_f1_score)}\") # Valid F1\n",
        "print(f\"Average Valid Precsion: {np.mean(valid_precision_score)}\") # Valid Precsion\n",
        "print(f\"Average Valid Recall: {np.mean(valid_recall_score)}\") # Valid Recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_dist = {\n",
        "    'rfc__n_estimators': [100, 300, 500],\n",
        "    'rfc__max_depth': [10, 20, 30, None],\n",
        "    'rfc__min_samples_split': [2, 5, 10],\n",
        "    'rfc__min_samples_leaf': [1, 2, 4],\n",
        "    'rfc__bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "train_pipeline = ImbPipeline([\n",
        "    ('preprocessor', processor),\n",
        "    ('smote', SMOTE(sampling_strategy=0.5, random_state=42)),\n",
        "    ('rfc', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "grid_rfc_search = GridSearchCV(train_pipeline, param_dist, cv=skf, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "\n",
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'f1': 'f1',\n",
        "    'precision': 'precision',\n",
        "    'recall': 'recall'\n",
        "}\n",
        "\n",
        "cv_results = cross_validate(\n",
        "    estimator=grid_rfc_search,\n",
        "    X=X_train,\n",
        "    y=y_train,\n",
        "    cv=skf,\n",
        "    scoring=scoring,\n",
        "    return_train_score=False,\n",
        "    return_estimator=True\n",
        ")\n",
        "\n",
        "grid_rfc_search.fit(X_train, y_train)\n",
        "best_rfc_model = grid_rfc_search.best_estimator_\n",
        "best_params = grid_rfc_search.best_params_\n",
        "\n",
        "valid_accuracy_score = cv_results['test_accuracy']\n",
        "valid_f1_score = cv_results['test_f1']\n",
        "valid_precision_score = cv_results['test_precision']\n",
        "valid_recall_score = cv_results['test_recall']\n",
        "\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"Average Valid Accuracy: {np.mean(valid_accuracy_score):.4f}\")\n",
        "print(f\"Average Valid F1 Score: {np.mean(valid_f1_score):.4f}\")\n",
        "print(f\"Average Valid Precision: {np.mean(valid_precision_score):.4f}\")\n",
        "print(f\"Average Valid Recall: {np.mean(valid_recall_score):.4f}\")\n",
        "\n",
        "print(\"\\nDetailed fold results:\")\n",
        "for fold in range(5):\n",
        "    print(f\"Fold {fold + 1}: \"\n",
        "          f\"Accuracy={valid_accuracy_score[fold]:.4f}, \"\n",
        "          f\"F1={valid_f1_score[fold]:.4f}, \"\n",
        "          f\"Precision={valid_precision_score[fold]:.4f}, \"\n",
        "          f\"Recall={valid_recall_score[fold]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rfc_model_5_pipe = ImbPipeline([\n",
        "    ('preprocessor', processor),\n",
        "    ('smote', SMOTE(sampling_strategy=0.5, random_state=42)),\n",
        "    ('rfc', RandomForestClassifier(n_estimators=300, random_state=42, \n",
        "                                  max_depth=35, min_samples_split=2, \n",
        "                                  min_samples_leaf=4, bootstrap=False))\n",
        "])\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scoring = ['accuracy', 'f1', 'precision', 'recall']\n",
        "cv_results = cross_validate(\n",
        "    rfc_model_5_pipe,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=skf,\n",
        "    scoring=scoring,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rfc_model_5_pipe.fit(X_train, y_train)\n",
        "y_rfc_model_5_pred = rfc_model_5_pipe.predict(X_train)\n",
        "\n",
        "print(\"\\nPerformance Metrics:\")\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train, y_pred=y_rfc_model_5_pred)}\")\n",
        "print(f\"CV Accuracy: {np.mean(cv_results['test_accuracy']):.4f}\")\n",
        "print(f\"CV F1: {np.mean(cv_results['test_f1']):.4f}\")\n",
        "print(f\"CV Precision: {np.mean(cv_results['test_precision']):.4f}\")\n",
        "print(f\"CV Recall: {np.mean(cv_results['test_recall']):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "extra_trees_model = ExtraTreesClassifier(n_estimators=1000, random_state=42, max_depth=5, min_samples_leaf=2, min_samples_split=2)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "valid_extra_tree_acc = cross_val_score(extra_trees_model, X_train_resampled, y_train_resampled, cv=skf)\n",
        "\n",
        "extra_trees_model.fit(X_train_resampled, y_train_resampled)\n",
        "y_extra_trees_pred = extra_trees_model.predict(X_train_resampled)\n",
        "\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train_resampled, y_pred=y_extra_trees_pred)}\")\n",
        "print(f\"Validation Accuracy: {valid_extra_tree_acc.mean()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "extra_trees_model_pipe = ImbPipeline([\n",
        "    ('preprocessor', processor),\n",
        "    ('smote', SMOTE(sampling_strategy=0.5, random_state=42)),\n",
        "    ('et', ExtraTreesClassifier(n_estimators=1000, random_state=42, max_depth=5, min_samples_leaf=2, min_samples_split=2))\n",
        "])\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scoring = ['accuracy', 'f1', 'precision', 'recall']\n",
        "cv_results = cross_validate(\n",
        "    extra_trees_model_pipe,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=skf,\n",
        "    scoring=scoring,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "extra_trees_model_pipe.fit(X_train, y_train)\n",
        "y_ext_pred = extra_trees_model_pipe.predict(X_train)\n",
        "\n",
        "print(\"\\nPerformance Metrics:\")\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train, y_pred=y_ext_pred)}\")\n",
        "print(f\"CV Accuracy: {np.mean(cv_results['test_accuracy']):.4f}\")\n",
        "print(f\"CV F1: {np.mean(cv_results['test_f1']):.4f}\")\n",
        "print(f\"CV Precision: {np.mean(cv_results['test_precision']):.4f}\")\n",
        "print(f\"CV Recall: {np.mean(cv_results['test_recall']):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rcVw159BpZe"
      },
      "source": [
        "## boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WQP2TILeFeu",
        "outputId": "7dc7512c-e5d6-4b89-f507-c04e90dad4be"
      },
      "outputs": [],
      "source": [
        "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "valid_gb = cross_val_score(gb_model, X_train_resampled, y_train_resampled, cv=skf)\n",
        "\n",
        "gb_model.fit(X_train_resampled, y_train_resampled)\n",
        "y_gb_pred = gb_model.predict(X_train_resampled)\n",
        "\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train_resampled, y_pred=y_gb_pred)}\")\n",
        "print(f\"Validation Accuracy: {valid_gb.mean()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_vald_gb_pred = cross_val_predict(gb_model, X_train_resampled, y_train_resampled, cv=skf)\n",
        "confusion_matrix(y_train_resampled, y_vald_gb_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "percison_gb_score = precision_score(y_true=y_train_resampled, y_pred=y_vald_gb_pred)\n",
        "recall_gb_score = recall_score(y_true=y_train_resampled, y_pred=y_vald_gb_pred)\n",
        "f1_gb_score = f1_score(y_true=y_train_resampled, y_pred=y_vald_gb_pred)\n",
        "print(f\"Precision Score: {percison_gb_score}\")\n",
        "print(f\"Recall Score: {recall_gb_score}\")\n",
        "print(f\"F1 Score: {f1_gb_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train_resampled.value_counts(normalize=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gb_model_3 = GradientBoostingClassifier(\n",
        "    n_estimators=300,           # More than 100, but not as heavy as 1000\n",
        "    learning_rate=0.05,         # Lower learning rate to improve generalization\n",
        "    max_depth=4,                # Slightly deeper to capture more patterns\n",
        "    subsample=0.8,              # Stochastic GBM to speed up training\n",
        "    max_features='sqrt',        # Use a subset of features for efficiency\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "valid_gb_3 = cross_val_score(gb_model_3, X_train_resampled, y_train_resampled, cv=skf)\n",
        "\n",
        "gb_model_3.fit(X_train_resampled, y_train_resampled)\n",
        "y_gb_3_pred = gb_model_3.predict(X_train_resampled)\n",
        "\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train_resampled, y_pred=y_gb_3_pred)}\")\n",
        "print(f\"Validation Accuracy: {valid_gb_3.mean()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_vald_gb3_pred = cross_val_predict(gb_model_3, X_train_resampled, y_train_resampled, cv=skf)\n",
        "confusion_matrix(y_train_resampled, y_vald_gb3_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "percison_gb3_score = precision_score(y_true=y_train_resampled, y_pred=y_vald_gb3_pred)\n",
        "recall_gb3_score = recall_score(y_true=y_train_resampled, y_pred=y_vald_gb3_pred)\n",
        "f1_gb3_score = f1_score(y_true=y_train_resampled, y_pred=y_vald_gb3_pred)\n",
        "print(f\"Precision Score: {percison_gb3_score}\")\n",
        "print(f\"Recall Score: {recall_gb3_score}\")\n",
        "print(f\"F1 Score: {f1_gb3_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gb_model_pipe = ImbPipeline([\n",
        "    ('preprocessor', processor),\n",
        "    ('smote', SMOTE(sampling_strategy=0.5, random_state=42)),\n",
        "    ('gb', GradientBoostingClassifier(\n",
        "    n_estimators=300,           # More than 100, but not as heavy as 1000\n",
        "    learning_rate=0.05,         # Lower learning rate to improve generalization\n",
        "    max_depth=4,                # Slightly deeper to capture more patterns\n",
        "    subsample=0.8,              # Stochastic GBM to speed up training\n",
        "    max_features='sqrt',        # Use a subset of features for efficiency\n",
        "    random_state=42\n",
        "))\n",
        "])\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scoring = ['accuracy', 'f1', 'precision', 'recall']\n",
        "cv_results = cross_validate(\n",
        "    gb_model_pipe,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=skf,\n",
        "    scoring=scoring,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "gb_model_pipe.fit(X_train, y_train)\n",
        "y_gb_model_pred = gb_model_pipe.predict(X_train)\n",
        "\n",
        "print(\"\\nPerformance Metrics:\")\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train, y_pred=y_gb_model_pred)}\")\n",
        "print(f\"CV Accuracy: {np.mean(cv_results['test_accuracy']):.4f}\")\n",
        "print(f\"CV F1: {np.mean(cv_results['test_f1']):.4f}\")\n",
        "print(f\"CV Precision: {np.mean(cv_results['test_precision']):.4f}\")\n",
        "print(f\"CV Recall: {np.mean(cv_results['test_recall']):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKqrRbDiETpf",
        "outputId": "ee8fd081-99fe-47c8-9bd5-1e3bc47112dc"
      },
      "outputs": [],
      "source": [
        "ada_boost_cl = AdaBoostClassifier(n_estimators=100, learning_rate=0.5, random_state=42)\n",
        "\n",
        "ada_boost_cl.fit(X_train_resampled, y_train_resampled)\n",
        "y_ada_cl_pred = ada_boost_cl.predict(X_train_resampled)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "valid_c1_ada_acc = cross_val_score(ada_boost_cl, X_train_resampled, y_train_resampled, cv=skf)\n",
        "\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train_resampled, y_pred=y_ada_cl_pred)}\")\n",
        "print(f\"Validation Accuracy: {valid_c1_ada_acc.mean()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5doxgXKtQHjO"
      },
      "outputs": [],
      "source": [
        "ada_boost = AdaBoostClassifier(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.3,\n",
        "    random_state=42\n",
        ")\n",
        "ada_boost.fit(X_train_resampled, y_train_resampled)\n",
        "y_ada_pred = ada_boost.predict(X_train_resampled)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "valid_ada_acc = cross_val_score(ada_boost, X_train_resampled, y_train_resampled, cv=skf)\n",
        "\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train_resampled, y_pred=y_ada_pred)}\")\n",
        "print(f\"Validation Accuracy: {valid_ada_acc.mean()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjlP7Jud9lX6"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 1.0],\n",
        "    'algorithm': ['SAMME', 'SAMME.R']\n",
        "}\n",
        "\n",
        "ada_boost_cl = AdaBoostClassifier(random_state=42)\n",
        "\n",
        "grid_search = GridSearchCV(ada_boost_cl, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
        "\n",
        "best_ada_boost = grid_search.best_estimator_\n",
        "\n",
        "y_pred = best_ada_boost.predict(X_train_resampled)\n",
        "train_accuracy = accuracy_score(y_train_resampled, y_pred)\n",
        "print(f\"Train Accuracy: {train_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ada_boost_grid = AdaBoostClassifier(\n",
        "    n_estimators=200,        \n",
        "    learning_rate=1.0,       \n",
        "    random_state=42,\n",
        "    algorithm='SAMME'\n",
        ")\n",
        "ada_boost_grid.fit(X_train_resampled, y_train_resampled)\n",
        "y_ada_grid_pred = ada_boost_grid.predict(X_train_resampled)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "valid_ada_grid_acc = cross_val_score(ada_boost_grid, X_train_resampled, y_train_resampled, cv=skf)\n",
        "\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train_resampled, y_pred=y_ada_grid_pred)}\")\n",
        "print(f\"Validation Accuracy: {valid_ada_grid_acc.mean()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_vald_ada_pred = cross_val_predict(ada_boost_grid, X_train_resampled, y_train_resampled, cv=skf)\n",
        "confusion_matrix(y_train_resampled, y_vald_ada_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "percison_ada_score = precision_score(y_true=y_train_resampled, y_pred=y_vald_ada_pred)\n",
        "recall_ada_score = recall_score(y_true=y_train_resampled, y_pred=y_vald_ada_pred)\n",
        "f1_ada_score = f1_score(y_true=y_train_resampled, y_pred=y_vald_ada_pred)\n",
        "print(f\"Precision Score: {percison_ada_score}\")\n",
        "print(f\"Recall Score: {recall_ada_score}\")\n",
        "print(f\"F1 Score: {f1_ada_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ada_model_pipe = ImbPipeline([\n",
        "    ('preprocessor', processor),\n",
        "    ('smote', SMOTE(sampling_strategy=0.5, random_state=42)),\n",
        "    ('ada', AdaBoostClassifier(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.3,\n",
        "    random_state=42\n",
        "))\n",
        "])\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scoring = ['accuracy', 'f1', 'precision', 'recall']\n",
        "cv_results = cross_validate(\n",
        "    ada_model_pipe,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=skf,\n",
        "    scoring=scoring,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "ada_model_pipe.fit(X_train, y_train)\n",
        "y_ada_model_pred = ada_model_pipe.predict(X_train)\n",
        "\n",
        "print(\"\\nPerformance Metrics:\")\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train, y_pred=y_ada_model_pred)}\")\n",
        "print(f\"CV Accuracy: {np.mean(cv_results['test_accuracy']):.4f}\")\n",
        "print(f\"CV F1: {np.mean(cv_results['test_f1']):.4f}\")\n",
        "print(f\"CV Precision: {np.mean(cv_results['test_precision']):.4f}\")\n",
        "print(f\"CV Recall: {np.mean(cv_results['test_recall']):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlKW8iI0EVLD",
        "outputId": "d18f4d4d-dd0a-4257-df0f-eb1a29c645c6"
      },
      "outputs": [],
      "source": [
        "xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "\n",
        "xgb_model.fit(X_train_resampled, y_train_resampled)\n",
        "y_xgb_pred = xgb_model.predict(X_train_resampled)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "valid_xg_acc = cross_val_score(xgb_model, X_train_resampled, y_train_resampled, cv=skf)\n",
        "\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train_resampled, y_pred=y_xgb_pred)}\")\n",
        "print(f\"Validation Accuracy: {valid_xg_acc.mean()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnKXrioH9pWj"
      },
      "outputs": [],
      "source": [
        "xgb_model_no_early_stop = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=4,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    gamma=1,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=1,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "valid_xg_no_acc = cross_val_score(xgb_model_no_early_stop, X_train_resampled, y_train_resampled, cv=skf)\n",
        "\n",
        "xgb_model_no_early_stop.fit(X_train_resampled, y_train_resampled)\n",
        "y_xgb_no_pred = xgb_model_no_early_stop.predict(X_train_resampled)\n",
        "\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train_resampled, y_pred=y_xgb_no_pred)}\")\n",
        "print(f\"Validation Accuracy: {valid_xg_no_acc.mean()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test_pred = xgb_model_no_early_stop.predict(X_test_preprocessor)\n",
        "y_test_proba = xgb_model_no_early_stop.predict_proba(X_test_preprocessor)[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_curve, roc_curve, auc\n",
        "\n",
        "# Accuracy\n",
        "test_acc = accuracy_score(y_test, y_test_pred)\n",
        "print(f\"Test Accuracy: {test_acc:.3f}\")\n",
        "\n",
        "# Precision-Recall Curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_test_proba)\n",
        "pr_auc = auc(recall, precision)\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_test_proba)\n",
        "roc_auc = auc(fpr, tpr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_vald_xgb_pred = cross_val_predict(xgb_model_no_early_stop, X_train_resampled, y_train_resampled, cv=skf)\n",
        "confusion_matrix(y_train_resampled, y_vald_xgb_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "percison_xgb_score = precision_score(y_true=y_train_resampled, y_pred=y_vald_xgb_pred)\n",
        "recall_xgb_score = recall_score(y_true=y_train_resampled, y_pred=y_vald_xgb_pred)\n",
        "f1_xgb_score = f1_score(y_true=y_train_resampled, y_pred=y_vald_xgb_pred)\n",
        "print(f\"Precision Score: {percison_xgb_score}\")\n",
        "print(f\"Recall Score: {recall_xgb_score}\")\n",
        "print(f\"F1 Score: {f1_xgb_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb_model_pipe = ImbPipeline([\n",
        "    ('preprocessor', processor),\n",
        "    ('smote', SMOTE(sampling_strategy=0.5, random_state=42)),\n",
        "    ('xgb', XGBClassifier(\n",
        "    n_estimators=250,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=4,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    gamma=1,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=1,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'\n",
        "))\n",
        "])\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scoring = ['accuracy', 'f1', 'precision', 'recall']\n",
        "cv_results = cross_validate(\n",
        "    xgb_model_pipe,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=skf,\n",
        "    scoring=scoring,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "xgb_model_pipe.fit(X_train, y_train)\n",
        "y_xgb_model_pred = xgb_model_pipe.predict(X_train)\n",
        "y_val_pred = xgb_model_pipe.predict(X_val)\n",
        "\n",
        "print(\"\\nPerformance Metrics:\")\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train, y_pred=y_xgb_model_pred)}\")\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n",
        "print(f\"CV Accuracy: {np.mean(cv_results['test_accuracy']):.4f}\")\n",
        "print(f\"CV F1: {np.mean(cv_results['test_f1']):.4f}\")\n",
        "print(f\"CV Precision: {np.mean(cv_results['test_precision']):.4f}\")\n",
        "print(f\"CV Recall: {np.mean(cv_results['test_recall']):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb_model_pipe = ImbPipeline([\n",
        "    ('preprocessor', processor),\n",
        "    ('smote', SMOTE(sampling_strategy=0.5, random_state=42)),\n",
        "    ('xgb', XGBClassifier(\n",
        "        n_estimators=250,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=4,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        gamma=1,\n",
        "        reg_alpha=0.1,\n",
        "        reg_lambda=1,\n",
        "        random_state=42,\n",
        "        eval_metric='logloss',\n",
        "        early_stopping_rounds=10  # Early stopping enabled\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Preprocess validation data using the pipeline's components\n",
        "X_val_preprocessed = xgb_model_pipe.named_steps['preprocessor'].transform(X_val)\n",
        "\n",
        "# Fit the model with early stopping\n",
        "xgb_model_pipe.fit(\n",
        "    X_train, \n",
        "    y_train,\n",
        "    xgb__eval_set=[(X_val_preprocessed, y_val)]  # Use preprocessed validation data\n",
        ")\n",
        "\n",
        "# Predictions and metrics (unchanged)\n",
        "y_xgb_model_pred = xgb_model_pipe.predict(X_train)\n",
        "y_val_pred = xgb_model_pipe.predict(X_val)\n",
        "\n",
        "print(\"\\nPerformance Metrics:\")\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train, y_pred=y_xgb_model_pred)}\")\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n",
        "print(f\"CV Accuracy: {np.mean(cv_results['test_accuracy']):.4f}\")\n",
        "print(f\"CV F1: {np.mean(cv_results['test_f1']):.4f}\")\n",
        "print(f\"CV Precision: {np.mean(cv_results['test_precision']):.4f}\")\n",
        "print(f\"CV Recall: {np.mean(cv_results['test_recall']):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTsB8I1W9ub-",
        "outputId": "1b9e713e-9fab-4c6c-a759-333279d01e52"
      },
      "outputs": [],
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "lgb_model = LGBMClassifier(\n",
        "    n_estimators=150,\n",
        "    learning_rate=0.05,\n",
        "    random_state=42,\n",
        "    max_depth=15,\n",
        "    num_leaves=33,\n",
        "    min_child_samples=19,\n",
        "    subsample=0.7,\n",
        "    colsample_bytree=0.8,\n",
        "    verbose=-1\n",
        ")\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "valid_lgb_acc = cross_val_score(lgb_model, X_train_resampled, y_train_resampled, cv=skf)\n",
        "\n",
        "lgb_model.fit(X_train_resampled, y_train_resampled)\n",
        "y_lgb_best_pred = lgb_model.predict(X_train_resampled)\n",
        "\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train_resampled, y_pred=y_lgb_best_pred)}\")\n",
        "print(f\"Validation Accuracy: {valid_lgb_acc.mean()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna\n",
        "\n",
        "# Objective function for optimization\n",
        "def objective(trial):\n",
        "    # Suggest hyperparameters\n",
        "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 1000)\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.2)\n",
        "    max_depth = trial.suggest_int(\"max_depth\", 3, 15)\n",
        "    num_leaves = trial.suggest_int(\"num_leaves\", 20, 100)\n",
        "    min_child_samples = trial.suggest_int(\"min_child_samples\", 10, 50)\n",
        "    subsample = trial.suggest_float(\"subsample\", 0.5, 1.0)\n",
        "    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.5, 1.0)\n",
        "\n",
        "    # Initialize model\n",
        "    model = LGBMClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        learning_rate=learning_rate,\n",
        "        max_depth=max_depth,\n",
        "        num_leaves=num_leaves,\n",
        "        min_child_samples=min_child_samples,\n",
        "        subsample=subsample,\n",
        "        colsample_bytree=colsample_bytree,\n",
        "        random_state=42\n",
        "    )\n",
        "    \n",
        "    # Perform cross-validation\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    scores = cross_val_score(model, X_train_resampled, y_train_resampled, cv=skf, scoring='accuracy')\n",
        "    return scores.mean()\n",
        "\n",
        "# Run optimization\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# Print best parameters\n",
        "print(\"Best parameters:\", study.best_params)\n",
        "print(\"Best score:\", study.best_value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lgb_model_grid = LGBMClassifier(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    random_state=42,\n",
        "    max_depth=12,\n",
        "    num_leaves=83,\n",
        "    min_child_samples=28,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.5,\n",
        "    verbose=-1\n",
        ")\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "valid_lgb_grid_acc = cross_val_score(lgb_model_grid, X_train_resampled, y_train_resampled, cv=skf)\n",
        "\n",
        "lgb_model_grid.fit(X_train_resampled, y_train_resampled)\n",
        "y_lgb_grid_pred = lgb_model_grid.predict(X_train_resampled)\n",
        "\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train_resampled, y_pred=y_lgb_grid_pred)}\")\n",
        "print(f\"Validation Accuracy: {valid_lgb_grid_acc.mean()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_vald_lgb_grid_pred = cross_val_predict(lgb_model_grid, X_train_resampled, y_train_resampled, cv=skf)\n",
        "confusion_matrix(y_train_resampled, y_vald_lgb_grid_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "percison_lgb_grid_score = precision_score(y_true=y_train_resampled, y_pred=y_vald_lgb_grid_pred)\n",
        "recall_lgb_grid_score = recall_score(y_true=y_train_resampled, y_pred=y_vald_lgb_grid_pred)\n",
        "f1_lgb_grid_score = f1_score(y_true=y_train_resampled, y_pred=y_vald_lgb_grid_pred)\n",
        "print(f\"Precision Score: {percison_lgb_grid_score}\")\n",
        "print(f\"Recall Score: {recall_lgb_grid_score}\")\n",
        "print(f\"F1 Score: {f1_lgb_grid_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "lgbm_model_pipe = ImbPipeline([\n",
        "    ('preprocessor', processor),\n",
        "    ('smote', SMOTE(sampling_strategy=0.5, random_state=42)),\n",
        "        ('lgbm', LGBMClassifier(\n",
        "        n_estimators=500,\n",
        "        learning_rate=0.05,\n",
        "        random_state=42,\n",
        "        max_depth=6,\n",
        "        num_leaves=31,\n",
        "        min_child_samples=28,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.5,\n",
        "        verbose=-1\n",
        "    ))\n",
        "])\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scoring = ['accuracy', 'f1', 'precision', 'recall']\n",
        "cv_results = cross_validate(\n",
        "    lgbm_model_pipe,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=skf,\n",
        "    scoring=scoring,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lgbm_model_pipe.fit(X_train, y_train)\n",
        "y_lgbm_model_pred = lgbm_model_pipe.predict(X_train)\n",
        "y_val_pred = lgbm_model_pipe.predict(X_val)\n",
        "\n",
        "print(\"\\nPerformance Metrics:\")\n",
        "print(f\"Train Accuracy: {accuracy_score(y_true=y_train, y_pred=y_lgbm_model_pred)}\")\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n",
        "print(f\"CV Accuracy: {np.mean(cv_results['test_accuracy']):.4f}\")\n",
        "print(f\"CV F1: {np.mean(cv_results['test_f1']):.4f}\")\n",
        "print(f\"CV Precision: {np.mean(cv_results['test_precision']):.4f}\")\n",
        "print(f\"CV Recall: {np.mean(cv_results['test_recall']):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPuS4rjWBs1J"
      },
      "source": [
        "## stacking (voting, stacking)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rfc_model  = RandomForestClassifier(\n",
        "    n_estimators=400, \n",
        "    random_state=42, \n",
        "    max_depth=15, \n",
        "    min_samples_split=2, \n",
        "    min_samples_leaf=4, \n",
        "    bootstrap=False)\n",
        "\n",
        "\n",
        "\n",
        "lgbm_model = LGBMClassifier(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    random_state=42,\n",
        "    max_depth=6,\n",
        "    num_leaves=31,\n",
        "    min_child_samples=28,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.5,\n",
        "    verbose=-1\n",
        ")\n",
        "\n",
        "\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=250,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=4,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    gamma=1,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=1,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('rf', rfc_model), ('lgbm', lgbm_model), ('xgb', xgb_model)],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "\n",
        "voting_pipeline = ImbPipeline([\n",
        "    ('preprocessor', processor),\n",
        "    ('smote', SMOTE(sampling_strategy=0.5, random_state=42)),\n",
        "    ('voting', voting_clf) \n",
        "])\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scoring = ['accuracy', 'f1', 'precision', 'recall']\n",
        "\n",
        "cv_results = cross_validate(\n",
        "    voting_pipeline,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=skf,\n",
        "    scoring=scoring,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "voting_pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = voting_pipeline.predict(X_train)\n",
        "y_val_pred = voting_pipeline.predict(X_val)\n",
        "\n",
        "print(\"\\nPerformance Metrics:\")\n",
        "print(f\"Train Accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n",
        "print(f\"CV Accuracy: {np.mean(cv_results['test_accuracy']):.4f}\")\n",
        "print(f\"CV F1: {np.mean(cv_results['test_f1']):.4f}\")\n",
        "print(f\"CV Precision: {np.mean(cv_results['test_precision']):.4f}\")\n",
        "print(f\"CV Recall: {np.mean(cv_results['test_recall']):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAWkvaCgFY7A"
      },
      "outputs": [],
      "source": [
        "rfc_model_5 = RandomForestClassifier(\n",
        "    n_estimators=400, \n",
        "    random_state=42, \n",
        "    max_depth=15, \n",
        "    min_samples_split=2, \n",
        "    min_samples_leaf=4, \n",
        "    bootstrap=False)\n",
        "\n",
        "\n",
        "\n",
        "lgb_model_grid = LGBMClassifier(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    random_state=42,\n",
        "    max_depth=12,\n",
        "    num_leaves=83,\n",
        "    min_child_samples=28,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.5,\n",
        "    verbose=-1\n",
        ")\n",
        "\n",
        "\n",
        "xgb_model_no_early_stop = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=4,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    gamma=1,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=1,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "voting_clf = VotingClassifier(estimators=[\n",
        "    ('rf', rfc_model_5),\n",
        "    ('lgbm', lgb_model_grid),\n",
        "    ('xgb', xgb_model_no_early_stop)\n",
        "], voting='soft', weights=[0.6, 0.2, 0.2])\n",
        "\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "valid_voting_acc = cross_val_score(voting_clf, X_train_resampled, y_train_resampled,\n",
        "                                   cv=skf, scoring='f1', n_jobs=-1)\n",
        "\n",
        "voting_clf.fit(X_train_resampled, y_train_resampled)\n",
        "y_voting_pred = voting_clf.predict(X_train_resampled)\n",
        "\n",
        "train_acc = accuracy_score(y_train_resampled, y_voting_pred)\n",
        "\n",
        "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
        "print(f\"Validation Accuracy: {valid_voting_acc.mean():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_vald_voting_pred = cross_val_predict(voting_clf, X_train_resampled, y_train_resampled, cv=skf)\n",
        "confusion_matrix(y_train_resampled, y_vald_voting_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "percison_voting_score = precision_score(y_true=y_train_resampled, y_pred=y_vald_voting_pred)\n",
        "recall_voting_score = recall_score(y_true=y_train_resampled, y_pred=y_vald_voting_pred)\n",
        "f1_voting_score = f1_score(y_true=y_train_resampled, y_pred=y_vald_voting_pred)\n",
        "print(f\"Precision Score: {percison_voting_score}\")\n",
        "print(f\"Recall Score: {recall_voting_score}\")\n",
        "print(f\"F1 Score: {f1_voting_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rfc_model  = RandomForestClassifier(\n",
        "    n_estimators=400, \n",
        "    random_state=42, \n",
        "    max_depth=15, \n",
        "    min_samples_split=2, \n",
        "    min_samples_leaf=4, \n",
        "    bootstrap=False)\n",
        "\n",
        "\n",
        "\n",
        "lgbm_model = LGBMClassifier(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    random_state=42,\n",
        "    max_depth=6,\n",
        "    num_leaves=31,\n",
        "    min_child_samples=28,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.5,\n",
        "    verbose=-1\n",
        ")\n",
        "\n",
        "\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=250,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=4,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    gamma=1,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=1,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "\n",
        "base_models = [\n",
        "    ('xgb', xgb_model),\n",
        "    ('rf', rfc_model),\n",
        "    ('lgb', lgbm_model)\n",
        "]\n",
        "\n",
        "meta_model = VotingClassifier(estimators=base_models, voting='soft')\n",
        "\n",
        "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=meta_model, n_jobs=-1)\n",
        "\n",
        "stacking_pipeline = ImbPipeline([\n",
        "    ('preprocessor', processor),\n",
        "    ('smote', SMOTE(sampling_strategy=0.5, random_state=42)),\n",
        "    ('stacking', stacking_clf) \n",
        "])\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scoring = ['accuracy', 'f1', 'precision', 'recall']\n",
        "\n",
        "cv_results = cross_validate(\n",
        "    stacking_pipeline,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=skf,\n",
        "    scoring=scoring,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "stacking_pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = stacking_pipeline.predict(X_train)\n",
        "y_val_pred = stacking_pipeline.predict(X_val)\n",
        "\n",
        "print(\"\\nPerformance Metrics:\")\n",
        "print(f\"Train Accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n",
        "print(f\"CV Accuracy: {np.mean(cv_results['test_accuracy']):.4f}\")\n",
        "print(f\"CV F1: {np.mean(cv_results['test_f1']):.4f}\")\n",
        "print(f\"CV Precision: {np.mean(cv_results['test_precision']):.4f}\")\n",
        "print(f\"CV Recall: {np.mean(cv_results['test_recall']):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rfc_model  = RandomForestClassifier(\n",
        "    n_estimators=400, \n",
        "    random_state=42, \n",
        "    max_depth=15, \n",
        "    min_samples_split=2, \n",
        "    min_samples_leaf=4, \n",
        "    bootstrap=False)\n",
        "\n",
        "\n",
        "\n",
        "lgbm_model = LGBMClassifier(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    random_state=42,\n",
        "    max_depth=6,\n",
        "    num_leaves=31,\n",
        "    min_child_samples=28,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.5,\n",
        "    verbose=-1\n",
        ")\n",
        "\n",
        "\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=250,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=4,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    gamma=1,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=1,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "\n",
        "base_models = [\n",
        "    ('xgb', xgb_model),\n",
        "    ('rf', rfc_model),\n",
        "    ('lgb', lgbm_model)\n",
        "]\n",
        "\n",
        "meta_model = XGBClassifier(\n",
        "    n_estimators=100, \n",
        "    learning_rate=0.05, \n",
        "    max_depth=3, \n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "stacking_clf_xgb = StackingClassifier(estimators=base_models, final_estimator=meta_model, n_jobs=-1)\n",
        "\n",
        "stacking_pipeline_xgb = ImbPipeline([\n",
        "    ('preprocessor', processor),\n",
        "    ('smote', SMOTE(sampling_strategy=0.5, random_state=42)),\n",
        "    ('stacking', stacking_clf_xgb) \n",
        "])\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scoring = ['accuracy', 'f1', 'precision', 'recall']\n",
        "\n",
        "cv_results = cross_validate(\n",
        "    stacking_pipeline_xgb,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=skf,\n",
        "    scoring=scoring,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "stacking_pipeline_xgb.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = stacking_pipeline_xgb.predict(X_train)\n",
        "y_val_pred = stacking_pipeline_xgb.predict(X_val)\n",
        "\n",
        "print(\"\\nPerformance Metrics:\")\n",
        "print(f\"Train Accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n",
        "print(f\"CV Accuracy: {np.mean(cv_results['test_accuracy']):.4f}\")\n",
        "print(f\"CV F1: {np.mean(cv_results['test_f1']):.4f}\")\n",
        "print(f\"CV Precision: {np.mean(cv_results['test_precision']):.4f}\")\n",
        "print(f\"CV Recall: {np.mean(cv_results['test_recall']):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rfc_model  = RandomForestClassifier(\n",
        "    n_estimators=400, \n",
        "    random_state=42, \n",
        "    max_depth=15, \n",
        "    min_samples_split=2, \n",
        "    min_samples_leaf=4, \n",
        "    bootstrap=False)\n",
        "\n",
        "\n",
        "\n",
        "lgbm_model = LGBMClassifier(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    random_state=42,\n",
        "    max_depth=6,\n",
        "    num_leaves=31,\n",
        "    min_child_samples=28,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.5,\n",
        "    verbose=-1\n",
        ")\n",
        "\n",
        "\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=250,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=4,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    gamma=1,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=1,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "\n",
        "base_models = [\n",
        "    ('xgb', xgb_model),\n",
        "    ('rf', rfc_model),\n",
        "    ('lgb', lgbm_model)\n",
        "]\n",
        "\n",
        "meta_model = LGBMClassifier(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    random_state=42,\n",
        "    max_depth=6,\n",
        "    num_leaves=31,\n",
        "    min_child_samples=28,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.5,\n",
        "    verbose=-1\n",
        ")\n",
        "\n",
        "stacking_clf_lgb = StackingClassifier(estimators=base_models, final_estimator=meta_model, n_jobs=-1)\n",
        "\n",
        "stacking_pipeline_lgb = ImbPipeline([\n",
        "    ('preprocessor', processor),\n",
        "    ('smote', SMOTE(sampling_strategy=0.5, random_state=42)),\n",
        "    ('stacking', stacking_clf_lgb) \n",
        "])\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scoring = ['accuracy', 'f1', 'precision', 'recall']\n",
        "\n",
        "cv_results = cross_validate(\n",
        "    stacking_pipeline_lgb,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=skf,\n",
        "    scoring=scoring,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "stacking_pipeline_lgb.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = stacking_pipeline_lgb.predict(X_train)\n",
        "y_val_pred = stacking_pipeline_lgb.predict(X_val)\n",
        "\n",
        "print(\"\\nPerformance Metrics:\")\n",
        "print(f\"Train Accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n",
        "print(f\"CV Accuracy: {np.mean(cv_results['test_accuracy']):.4f}\")\n",
        "print(f\"CV F1: {np.mean(cv_results['test_f1']):.4f}\")\n",
        "print(f\"CV Precision: {np.mean(cv_results['test_precision']):.4f}\")\n",
        "print(f\"CV Recall: {np.mean(cv_results['test_recall']):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rfc_model  = RandomForestClassifier(\n",
        "    n_estimators=400, \n",
        "    random_state=42, \n",
        "    max_depth=15, \n",
        "    min_samples_split=2, \n",
        "    min_samples_leaf=4, \n",
        "    bootstrap=False)\n",
        "\n",
        "\n",
        "\n",
        "lgbm_model = LGBMClassifier(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    random_state=42,\n",
        "    max_depth=6,\n",
        "    num_leaves=31,\n",
        "    min_child_samples=28,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.5,\n",
        "    verbose=-1\n",
        ")\n",
        "\n",
        "\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=250,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=4,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    gamma=1,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=1,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "\n",
        "base_models = [\n",
        "    ('xgb', xgb_model),\n",
        "    ('rf', rfc_model),\n",
        "    ('lgb', lgbm_model)\n",
        "]\n",
        "\n",
        "meta_model = LogisticRegression()\n",
        "\n",
        "\n",
        "stacking_clf_log = StackingClassifier(estimators=base_models, final_estimator=meta_model, n_jobs=-1)\n",
        "\n",
        "stacking_pipeline_log = ImbPipeline([\n",
        "    ('preprocessor', processor),\n",
        "    ('smote', SMOTE(sampling_strategy=0.5, random_state=42)),\n",
        "    ('stacking', stacking_clf_log) \n",
        "])\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scoring = ['accuracy', 'f1', 'precision', 'recall']\n",
        "\n",
        "cv_results = cross_validate(\n",
        "    stacking_pipeline_log,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=skf,\n",
        "    scoring=scoring,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "stacking_pipeline_log.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = stacking_pipeline_log.predict(X_train)\n",
        "y_val_pred = stacking_pipeline_log.predict(X_val)\n",
        "\n",
        "print(\"\\nPerformance Metrics:\")\n",
        "print(f\"Train Accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n",
        "print(f\"CV Accuracy: {np.mean(cv_results['test_accuracy']):.4f}\")\n",
        "print(f\"CV F1: {np.mean(cv_results['test_f1']):.4f}\")\n",
        "print(f\"CV Precision: {np.mean(cv_results['test_precision']):.4f}\")\n",
        "print(f\"CV Recall: {np.mean(cv_results['test_recall']):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stacking_pipeline_log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_models = [\n",
        "    ('xgb', xgb_model_no_early_stop),\n",
        "    ('rf', rfc_model_5),\n",
        "    ('lgb', lgb_model_grid)\n",
        "]\n",
        "\n",
        "meta_model = LGBMClassifier(n_estimators=100, learning_rate=0.05, random_state=42)\n",
        "\n",
        "\n",
        "# Stacking Classifier\n",
        "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=meta_model, n_jobs=-1)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "valid_stacking_acc = cross_val_score(stacking_clf, X_train_resampled, y_train_resampled,\n",
        "                                     cv=skf, scoring='f1', n_jobs=-1)\n",
        "\n",
        "stacking_clf.fit(X_train_resampled, y_train_resampled)\n",
        "y_stacking_pred = stacking_clf.predict(X_train_resampled)\n",
        "\n",
        "train_stacking_lgb_acc = accuracy_score(y_train_resampled, y_stacking_pred)\n",
        "\n",
        "print(f\"Train Accuracy: {train_stacking_lgb_acc:.4f}\")\n",
        "print(f\"Validation Accuracy: {valid_stacking_acc.mean():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_vald_stacking_pred = cross_val_predict(stacking_clf, X_train_resampled, y_train_resampled, cv=skf)\n",
        "confusion_matrix(y_train_resampled, y_vald_stacking_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "percison_stacking_score = precision_score(y_true=y_train_resampled, y_pred=y_vald_stacking_pred)\n",
        "recall_stacking_score = recall_score(y_true=y_train_resampled, y_pred=y_vald_stacking_pred)\n",
        "f1_stacking_score = f1_score(y_true=y_train_resampled, y_pred=y_vald_stacking_pred)\n",
        "print(f\"Precision Score: {percison_stacking_score}\")\n",
        "print(f\"Recall Score: {recall_stacking_score}\")\n",
        "print(f\"F1 Score: {f1_stacking_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fW_qSIW3FY3x"
      },
      "outputs": [],
      "source": [
        "base_models = [\n",
        "    ('xgb', xgb_model_no_early_stop),\n",
        "    ('rf', rfc_model_5),\n",
        "    ('lgb', lgb_model_grid)\n",
        "]\n",
        "\n",
        "meta_model = LogisticRegression(C=1, random_state=42, max_iter=1000)\n",
        "\n",
        "# Stacking Classifier\n",
        "stacking_clf_log = StackingClassifier(estimators=base_models, final_estimator=meta_model, n_jobs=-1)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "valid_stacking_log_acc = cross_val_score(stacking_clf_log, X_train_resampled, y_train_resampled,\n",
        "                                     cv=skf, scoring='f1', n_jobs=-1)\n",
        "\n",
        "stacking_clf_log.fit(X_train_resampled, y_train_resampled)\n",
        "y_stacking_log_pred = stacking_clf_log.predict(X_train_resampled)\n",
        "\n",
        "train_stacking_log_acc = accuracy_score(y_train_resampled, y_stacking_log_pred)\n",
        "\n",
        "print(f\"Train Accuracy: {train_stacking_log_acc:.4f}\")\n",
        "print(f\"Validation Accuracy: {valid_stacking_log_acc.mean():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_vald_stacking_log_pred = cross_val_predict(stacking_clf_log, X_train_resampled, y_train_resampled, cv=skf)\n",
        "confusion_matrix(y_train_resampled, y_vald_stacking_log_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "percison_stacking_log_score = precision_score(y_true=y_train_resampled, y_pred=y_vald_stacking_log_pred)\n",
        "recall_stacking_log_score = recall_score(y_true=y_train_resampled, y_pred=y_vald_stacking_log_pred)\n",
        "f1_stacking_log_score = f1_score(y_true=y_train_resampled, y_pred=y_vald_stacking_log_pred)\n",
        "print(f\"Precision Score: {percison_stacking_log_score}\")\n",
        "print(f\"Recall Score: {recall_stacking_log_score}\")\n",
        "print(f\"F1 Score: {f1_stacking_log_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    # Base models hyperparameters\n",
        "    xgb_params = {\n",
        "        'n_estimators': trial.suggest_int('xgb_n_estimators', 100, 1000),\n",
        "        'max_depth': trial.suggest_int('xgb_max_depth', 3, 10),\n",
        "        'learning_rate': trial.suggest_float('xgb_learning_rate', 0.01, 0.3),\n",
        "        'subsample': trial.suggest_float('xgb_subsample', 0.5, 1.0)\n",
        "    }\n",
        "\n",
        "    rf_params = {\n",
        "        'n_estimators': trial.suggest_int('rf_n_estimators', 100, 1000),\n",
        "        'max_depth': trial.suggest_int('rf_max_depth', 5, 15),\n",
        "        'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 10)\n",
        "    }\n",
        "\n",
        "    lgb_params = {\n",
        "        'n_estimators': trial.suggest_int('lgb_n_estimators', 100, 1000),\n",
        "        'learning_rate': trial.suggest_float('lgb_learning_rate', 0.01, 0.3),\n",
        "        'num_leaves': trial.suggest_int('lgb_num_leaves', 31, 150)\n",
        "    }\n",
        "\n",
        "    # Meta-model parameters\n",
        "    logreg_params = {\n",
        "        'C': trial.suggest_float('logreg_C', 0.01, 10.0),\n",
        "        'max_iter': trial.suggest_int('logreg_max_iter', 100, 1000)\n",
        "    }\n",
        "\n",
        "    # Build models\n",
        "    xgb = XGBClassifier(**xgb_params, random_state=42)\n",
        "    rf = RandomForestClassifier(**rf_params, random_state=42)\n",
        "    lgb = LGBMClassifier(**lgb_params, random_state=42)\n",
        "\n",
        "    base_models = [\n",
        "        ('xgb', xgb),\n",
        "        ('rf', rf),\n",
        "        ('lgb', lgb)\n",
        "    ]\n",
        "\n",
        "    meta_model = LogisticRegression(**logreg_params, random_state=42)\n",
        "\n",
        "    stacking_clf = StackingClassifier(estimators=base_models, final_estimator=meta_model, n_jobs=-1)\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    f1 = cross_val_score(stacking_clf, X_train_resampled, y_train_resampled, cv=skf, scoring='f1', n_jobs=-1).mean()\n",
        "\n",
        "    return f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# Print best results\n",
        "print(\"Best F1 Score:\", study.best_value)\n",
        "print(\"Best Params:\", study.best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_params = study.best_params\n",
        "xgb_best = XGBClassifier(n_estimators=best_params['xgb_n_estimators'],\n",
        "                         max_depth=best_params['xgb_max_depth'],\n",
        "                         learning_rate=best_params['xgb_learning_rate'],\n",
        "                         subsample=best_params['xgb_subsample'],\n",
        "                         random_state=42)\n",
        "\n",
        "rf_best = RandomForestClassifier(n_estimators=best_params['rf_n_estimators'],\n",
        "                                 max_depth=best_params['rf_max_depth'],\n",
        "                                 min_samples_split=best_params['rf_min_samples_split'],\n",
        "                                 random_state=42)\n",
        "\n",
        "lgb_best = LGBMClassifier(n_estimators=best_params['lgb_n_estimators'],\n",
        "                          learning_rate=best_params['lgb_learning_rate'],\n",
        "                          num_leaves=best_params['lgb_num_leaves'],\n",
        "                          random_state=42)\n",
        "\n",
        "meta_best = LogisticRegression(C=best_params['logreg_C'],\n",
        "                                max_iter=best_params['logreg_max_iter'],\n",
        "                                random_state=42)\n",
        "\n",
        "# Final Stacking Model\n",
        "final_stacking_clf = StackingClassifier(estimators=[('xgb', xgb_best), ('rf', rf_best), ('lgb', lgb_best)],\n",
        "                                        final_estimator=meta_best, n_jobs=-1)\n",
        "\n",
        "final_stacking_clf.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "print(\"Final Model Trained with Optimized Hyperparameters!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_stacking_final_pred = final_stacking_clf.predict(X_train_resampled)\n",
        "valid_stacking_final_acc = cross_val_score(final_stacking_clf, X_train_resampled, y_train_resampled,\n",
        "                                     cv=skf, scoring='f1', n_jobs=-1)\n",
        "y_vald_stacking_final_pred = cross_val_predict(final_stacking_clf, X_train_resampled, y_train_resampled, cv=skf)\n",
        "train_stacking_final_acc = accuracy_score(y_train_resampled, y_stacking_final_pred)\n",
        "percison_stacking_final_score = precision_score(y_true=y_train_resampled, y_pred=y_vald_stacking_final_pred)\n",
        "recall_stacking_final_score = recall_score(y_true=y_train_resampled, y_pred=y_vald_stacking_final_pred)\n",
        "f1_stacking_final_score = f1_score(y_true=y_train_resampled, y_pred=y_vald_stacking_final_pred)\n",
        "\n",
        "print(f\"Precision Score: {percison_stacking_final_score}\")\n",
        "print(f\"Recall Score: {recall_stacking_final_score}\")\n",
        "print(f\"F1 Score: {f1_stacking_final_score}\")\n",
        "print(f\"Train Accuracy: {train_stacking_final_acc:.4f}\")\n",
        "print(f\"Validation Accuracy: {valid_stacking_final_acc.mean():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09cWHtQ292cr"
      },
      "source": [
        "# over sample vs under sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbT-trYt91um"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, sampler, X_train, y_train, X_test, y_test):\n",
        "    pipeline = ImbPipeline([\n",
        "        ('preprocessor', processor),\n",
        "        ('sampler', sampler),\n",
        "        ('classifier', model)\n",
        "    ])\n",
        "\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:, 1])\n",
        "\n",
        "    return accuracy, precision, recall, f1, roc_auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhHFXdbB-Ghr"
      },
      "outputs": [],
      "source": [
        "# List of models and sampling techniques\n",
        "models = [xgb_model_no_early_stop, rfc_model_5, lgb_model_grid, voting_clf, stacking_clf]\n",
        "samplers = [\n",
        "    SMOTE(random_state=42, sampling_strategy=0.5),\n",
        "    RandomUnderSampler(random_state=42)\n",
        "]\n",
        "sampler_names = ['SMOTE', 'Undersampling']\n",
        "\n",
        "# Evaluate and store results\n",
        "results = []\n",
        "\n",
        "for model in models:\n",
        "    for sampler, sampler_name in zip(samplers, sampler_names):\n",
        "        accuracy, precision, recall, f1, roc_auc = evaluate_model(model, sampler, X_train, y_train, X_test, y_test)\n",
        "        results.append({\n",
        "            'Model': model.__class__.__name__,\n",
        "            'Sampler': sampler_name,\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision': precision,\n",
        "            'Recall': recall,\n",
        "            'F1 Score': f1,\n",
        "            'ROC-AUC': roc_auc\n",
        "        })\n",
        "\n",
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY-9ZgDd-ml2"
      },
      "source": [
        "# models comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AaaTMrkTyzce",
        "outputId": "79354740-9e9c-445f-ad14-3847a24e1d67"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    'Random Forest': rfc_model_5,\n",
        "    'lgbm': lgb_model_grid,\n",
        "    'XGBoost': xgb_model_no_early_stop,\n",
        "    'Voting': voting_clf,\n",
        "    'Stacking_lgb': stacking_clf_log\n",
        "\n",
        "}\n",
        "\n",
        "# Ensure models are trained\n",
        "for name, model in models.items():\n",
        "    if not hasattr(model, \"fit\"):  # Check if model supports fitting\n",
        "        continue\n",
        "    print(f\"Training {name}...\")\n",
        "    model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "print(\"All models trained. Proceeding with evaluation.\")\n",
        "\n",
        "# Colors for plotting\n",
        "colors = ['b', 'g', 'r', 'c', 'm']\n",
        "\n",
        "# Figure setup\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "### 📌 Step 1: Plot ROC Curves ###\n",
        "plt.subplot(1, 2, 1)\n",
        "for (name, model), color in zip(models.items(), colors):\n",
        "    # Predict probabilities\n",
        "    y_proba = model.predict_proba(X_test_preprocessor)[:, 1]\n",
        "\n",
        "    # Compute ROC curve\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.plot(fpr, tpr, color=color, lw=2, label=f\"{name} (AUC = {roc_auc:.3f})\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.legend()\n",
        "\n",
        "### 📌 Step 2: Plot PR Curves ###\n",
        "plt.subplot(1, 2, 2)\n",
        "for (name, model), color in zip(models.items(), colors):\n",
        "    # Predict probabilities\n",
        "    y_proba = model.predict_proba(X_test_preprocessor)[:, 1]\n",
        "\n",
        "    # Compute Precision-Recall curve\n",
        "    precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
        "    pr_auc = auc(recall, precision)\n",
        "\n",
        "    plt.plot(recall, precision, color=color, lw=2, label=f\"{name} (AUC = {pr_auc:.3f})\")\n",
        "\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7eNBrvbgmXe4",
        "outputId": "bde26a95-d422-42fc-dcf6-fa70c09a80d4"
      },
      "outputs": [],
      "source": [
        "y_valid_voting_prob = cross_val_predict(voting_clf, X_train_resampled, y_train_resampled, cv=3, method='predict_proba')\n",
        "y_valid_stacking_prob = cross_val_predict(stacking_clf_log, X_train_resampled, y_train_resampled, cv=3, method='predict_proba')\n",
        "y_valid_xgb_prob = cross_val_predict(xgb_model_no_early_stop, X_train_resampled, y_train_resampled, cv=3, method='predict_proba')\n",
        "y_valid_rf_prob = cross_val_predict(rfc_model_5, X_train_resampled, y_train_resampled, cv=3, method='predict_proba')\n",
        "y_valid_lgb_prob = cross_val_predict(lgb_model_grid, X_train_resampled, y_train_resampled, cv=3, method='predict_proba')\n",
        "y_valid_gb_prob = cross_val_predict(gb_model_3, X_train_resampled, y_train_resampled, cv=3, method='predict_proba')\n",
        "\n",
        "precision_rf, recall_rf, rf_thresholds = precision_recall_curve(y_train_resampled, y_valid_rf_prob[:, 1])\n",
        "precision_xgb, recall_xgb, xgb_thresholds = precision_recall_curve(y_train_resampled, y_valid_xgb_prob[:, 1])\n",
        "precision_lgb, recall_lgb, lgb_thresholds = precision_recall_curve(y_train_resampled, y_valid_lgb_prob[:, 1])\n",
        "precision_voting, recall_voting, voting_thresholds = precision_recall_curve(y_train_resampled, y_valid_voting_prob[:, 1])\n",
        "precision_stacking, recall_stacking, stacking_thresholds = precision_recall_curve(y_train_resampled, y_valid_stacking_prob[:, 1])\n",
        "precision_gb, recall_gb, gb_thresholds = precision_recall_curve(y_train_resampled, y_valid_gb_prob[:, 1])\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall_rf[:-1], precision_rf[:-1], label='Random Forest', color='red')\n",
        "plt.plot(recall_xgb[:-1], precision_xgb[:-1], label='XGBoost', color='green')\n",
        "plt.plot(recall_lgb[:-1], precision_lgb[:-1], label='LightGBM', color='purple')\n",
        "plt.plot(recall_voting[:-1], precision_voting[:-1], label='Voting Classifier', color='orange')\n",
        "plt.plot(recall_stacking[:-1], precision_stacking[:-1], label='Stacking Classifier', color='brown')\n",
        "plt.plot(recall_gb[:-1], precision_gb[:-1], label='GB Classifier', color='yellow')\n",
        "\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curves for Different Models')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "fPvzSi8_Rdz0",
        "outputId": "2e58be02-dda6-4165-e532-66ec73552c51"
      },
      "outputs": [],
      "source": [
        "fpr_rf, tpr_rf, _ = roc_curve(y_train_resampled, y_valid_rf_prob[:, 1])\n",
        "fpr_xgb, tpr_xgb, _ = roc_curve(y_train_resampled, y_valid_xgb_prob[:, 1])\n",
        "fpr_lgb, tpr_lgb, _ = roc_curve(y_train_resampled, y_valid_lgb_prob[:, 1])\n",
        "fpr_voting, tpr_voting, _ = roc_curve(y_train_resampled, y_valid_voting_prob[:, 1])\n",
        "fpr_stacking, tpr_stacking, _ = roc_curve(y_train_resampled, y_valid_stacking_prob[:, 1])\n",
        "fpr_gb, tpr_gb, _ = roc_curve(y_train_resampled, y_valid_gb_prob[:, 1])\n",
        "\n",
        "\n",
        "auc_rf = auc(fpr_rf, tpr_rf)\n",
        "auc_xgb = auc(fpr_xgb, tpr_xgb)\n",
        "auc_lgb = auc(fpr_lgb, tpr_lgb)\n",
        "auc_voting = auc(fpr_voting, tpr_voting)\n",
        "auc_stacking = auc(fpr_stacking, tpr_stacking)\n",
        "auc_gb = auc(fpr_gb, tpr_gb)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {auc_rf:.3f})', color='red')\n",
        "plt.plot(fpr_xgb, tpr_xgb, label=f'XGBoost (AUC = {auc_xgb:.3f})', color='green')\n",
        "plt.plot(fpr_lgb, tpr_lgb, label=f'LightGBM (AUC = {auc_lgb:.3f})', color='purple')\n",
        "plt.plot(fpr_voting, tpr_voting, label=f'Voting (AUC = {auc_voting:.3f})', color='orange')\n",
        "plt.plot(fpr_stacking, tpr_stacking, label=f'Stacking (AUC = {auc_stacking:.3f})', color='brown')\n",
        "plt.plot(fpr_gb, tpr_gb, label=f'Gb (AUC = {auc_gb:.3f})', color='yellow')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Guess')\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves for Different Models')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_valid_voting_prob = cross_val_predict(voting_pipeline, X_train, y_train, cv=3, method='predict_proba')\n",
        "y_valid_stacking_xgb_prob = cross_val_predict(stacking_pipeline_xgb, X_train, y_train, cv=3, method='predict_proba')\n",
        "y_valid_stacking_log_prob = cross_val_predict(stacking_pipeline_log, X_train, y_train, cv=3, method='predict_proba')\n",
        "y_valid_xgb_prob = cross_val_predict(xgb_model_pipe, X_train, y_train, cv=3, method='predict_proba')\n",
        "y_valid_rf_prob = cross_val_predict(rfc_model_5_pipe, X_train, y_train, cv=3, method='predict_proba')\n",
        "y_valid_lgb_prob = cross_val_predict(lgbm_model_pipe, X_train, y_train, cv=3, method='predict_proba')\n",
        "y_valid_gb_prob = cross_val_predict(gb_model_pipe, X_train, y_train, cv=3, method='predict_proba')\n",
        "\n",
        "precision_rf, recall_rf, rf_thresholds = precision_recall_curve(y_train, y_valid_rf_prob[:, 1])\n",
        "precision_xgb, recall_xgb, xgb_thresholds = precision_recall_curve(y_train, y_valid_xgb_prob[:, 1])\n",
        "precision_lgb, recall_lgb, lgb_thresholds = precision_recall_curve(y_train, y_valid_lgb_prob[:, 1])\n",
        "precision_voting, recall_voting, voting_thresholds = precision_recall_curve(y_train, y_valid_voting_prob[:, 1])\n",
        "precision_stacking_xgb, recall_stacking_xgb, stacking_thresholds_xgb = precision_recall_curve(y_train, y_valid_stacking_log_prob[:, 1])\n",
        "precision_stacking, recall_stacking, stacking_thresholds = precision_recall_curve(y_train, y_valid_lgb_prob[:, 1])\n",
        "precision_gb, recall_gb, gb_thresholds = precision_recall_curve(y_train, y_valid_gb_prob[:, 1])\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall_rf[:-1], precision_rf[:-1], label='Random Forest', color='red')\n",
        "plt.plot(recall_xgb[:-1], precision_xgb[:-1], label='XGBoost', color='green')\n",
        "plt.plot(recall_lgb[:-1], precision_lgb[:-1], label='LightGBM', color='purple')\n",
        "plt.plot(recall_voting[:-1], precision_voting[:-1], label='Voting Classifier', color='orange')\n",
        "plt.plot(recall_stacking[:-1], precision_stacking[:-1], label='Stacking Classifier', color='brown')\n",
        "plt.plot(recall_stacking_xgb[:-1], precision_stacking_xgb[:-1], label='Stacking Classifier', color='blue')\n",
        "plt.plot(recall_gb[:-1], precision_gb[:-1], label='GB Classifier', color='yellow')\n",
        "\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curves for Different Models')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fpr_rf, tpr_rf, _ = roc_curve(y_train, y_valid_rf_prob[:, 1])\n",
        "fpr_xgb, tpr_xgb, _ = roc_curve(y_train, y_valid_xgb_prob[:, 1])\n",
        "fpr_lgb, tpr_lgb, _ = roc_curve(y_train, y_valid_lgb_prob[:, 1])\n",
        "fpr_voting, tpr_voting, _ = roc_curve(y_train, y_valid_voting_prob[:, 1])\n",
        "fpr_stacking, tpr_stacking, _ = roc_curve(y_train, y_valid_stacking_log_prob[:, 1])\n",
        "fpr_stacking_xgb, tpr_stacking_xgb, _ = roc_curve(y_train, y_valid_stacking_xgb_prob[:, 1])\n",
        "fpr_gb, tpr_gb, _ = roc_curve(y_train, y_valid_gb_prob[:, 1])\n",
        "\n",
        "\n",
        "auc_rf = auc(fpr_rf, tpr_rf)\n",
        "auc_xgb = auc(fpr_xgb, tpr_xgb)\n",
        "auc_lgb = auc(fpr_lgb, tpr_lgb)\n",
        "auc_voting = auc(fpr_voting, tpr_voting)\n",
        "auc_stacking = auc(fpr_stacking, tpr_stacking)\n",
        "auc_stacking_xgb = auc(fpr_stacking_xgb, tpr_stacking_xgb)\n",
        "auc_gb = auc(fpr_gb, tpr_gb)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {auc_rf:.3f})', color='red')\n",
        "plt.plot(fpr_xgb, tpr_xgb, label=f'XGBoost (AUC = {auc_xgb:.3f})', color='green')\n",
        "plt.plot(fpr_lgb, tpr_lgb, label=f'LightGBM (AUC = {auc_lgb:.3f})', color='purple')\n",
        "plt.plot(fpr_voting, tpr_voting, label=f'Voting (AUC = {auc_voting:.3f})', color='orange')\n",
        "plt.plot(fpr_stacking, tpr_stacking, label=f'Stacking (AUC = {auc_stacking:.3f})', color='brown')\n",
        "plt.plot(fpr_stacking_xgb, tpr_stacking_xgb, label=f'Stacking (AUC = {auc_stacking_xgb:.3f})', color='blue')\n",
        "plt.plot(fpr_gb, tpr_gb, label=f'Gb (AUC = {auc_gb:.3f})', color='yellow')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Guess')\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves for Different Models')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reHkUOU0jpLT"
      },
      "source": [
        "# ROC, precision and recall Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_valid_voting_pred = cross_val_predict(voting_pipeline, X_train, y_train, cv=3, method='predict')\n",
        "confusion_matrix(y_train, y_valid_voting_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "percison_rfc5_score = precision_score(y_true=y_train, y_pred=y_valid_voting_prob)\n",
        "recall_rfc5_score = recall_score(y_true=y_train, y_pred=y_valid_voting_prob)\n",
        "f1_rfc5_score = f1_score(y_true=y_train, y_pred=y_valid_voting_prob)\n",
        "print(f\"Precision Score: {percison_rfc5_score}\")\n",
        "print(f\"Recall Score: {recall_rfc5_score}\")\n",
        "print(f\"F1 Score: {f1_rfc5_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3BsVvFHxlUP5",
        "outputId": "6097affc-e21f-46e0-c00b-653df9f9e37f"
      },
      "outputs": [],
      "source": [
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "y_valid_voting_prob = cross_val_predict(voting_pipeline, X_train, y_train, cv=3, method='predict_proba')\n",
        "\n",
        "precision_voting, recall_voting, voting_thresholds = precision_recall_curve( y_train, y_valid_voting_prob[:, 1])\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall_voting, precision_voting, label='voting Classifier', color='orange')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve for voting Model')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_scores = y_valid_voting_prob[:, 1]\n",
        "\n",
        "# Compute precision, recall, and thresholds\n",
        "precision_voting, recall_voting, voting_thresholds = precision_recall_curve(y_train, y_scores)\n",
        "\n",
        "# Calculate F1 scores for each threshold\n",
        "f1_scores = [f1_score(y_train, (y_scores >= t).astype(int)) for t in voting_thresholds]\n",
        "\n",
        "# Find the threshold that maximizes the F1 score\n",
        "best_threshold_idx = np.argmax(f1_scores)\n",
        "best_threshold = voting_thresholds[best_threshold_idx]\n",
        "best_f1 = f1_scores[best_threshold_idx]\n",
        "\n",
        "print(f\"Best Threshold (F1 Score): {best_threshold:.4f}\")\n",
        "print(f\"Best F1 Score: {best_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_best = (y_scores >= best_threshold).astype(int)\n",
        "\n",
        "# Compute precision and recall at the best threshold\n",
        "precision_best = precision_score(y_train, y_pred_best)\n",
        "recall_best = recall_score(y_train, y_train)\n",
        "\n",
        "print(f\"Precision at Best Threshold: {precision_best:.4f}\")\n",
        "print(f\"Recall at Best Threshold: {recall_best:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall_voting, precision_voting, label='Precision-Recall Curve')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve for Voting Model')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "# Plot the best threshold point\n",
        "plt.scatter([recall_voting[best_threshold_idx]], [precision_voting[best_threshold_idx]], color='red', s=100, label=f'Best Threshold (F1={best_f1:.2f})')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "recall_voting[best_threshold_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jb5tURT7pUM_",
        "outputId": "534edf73-e029-4989-bc37-c922214effb5"
      },
      "outputs": [],
      "source": [
        "precision_voting, recall_voting, thresholds = precision_recall_curve(y_train, y_scores)\n",
        "\n",
        "target_recall = 0.42\n",
        "threshold_index = np.argmin(np.abs(recall_voting - target_recall))\n",
        "best_recal_threshold = thresholds[threshold_index]\n",
        "\n",
        "print(f\"Threshold for recall ~ {target_recall}: {best_recal_threshold:.4f}\")\n",
        "\n",
        "y_pred = (y_valid_voting_prob[:, 1] >= best_recal_threshold).astype(int)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_train, y_pred)\n",
        "precision = precision_score(y_train, y_pred)\n",
        "recall = recall_score(y_train, y_pred)\n",
        "f1 = f1_score(y_train, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "conf_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimal_idx = max(range(len(recall_voting)), key=lambda i: recall_voting[i] >= 0.42 and precision_voting[i])\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "print(f\"Optimal Threshold for Recall ≥ 0.83: {optimal_threshold:.2f}\")\n",
        "print(f\"Precision at this threshold: {precision_voting[optimal_idx]:.2f}\")\n",
        "print(f\"Recall at this threshold: {recall_voting[optimal_idx]:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "5rzJwNtHpgkU",
        "outputId": "1c1f8ddb-b20f-42a6-f5ac-cf7e95c89a87"
      },
      "outputs": [],
      "source": [
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=[0, 1])\n",
        "disp.plot(cmap='Blues')\n",
        "plt.title(f'Confusion Matrix at Recall = {target_recall}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiZyFG3UTC5N"
      },
      "source": [
        "# Test Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExDEz8xbt-rm"
      },
      "outputs": [],
      "source": [
        "model_pipeline = ImbPipeline([\n",
        "    ('preprocessor', processor),\n",
        "    ('smote', SMOTE(sampling_strategy=0.5, random_state=42)),\n",
        "    ('best_model', voting_clf)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swEWE2ytgJUY",
        "outputId": "a8e079b0-905b-4258-cfca-0e85457bc181"
      },
      "outputs": [],
      "source": [
        "y_voting_test_pred = model_pipeline.predict(X_test)\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test, y_voting_test_pred)}\") # Test accuracy\n",
        "print(f\"Test F1 Score: {f1_score(y_test, y_voting_test_pred)}\") # Test F1\n",
        "print(f\"Test Precsion: {precision_score(y_test, y_voting_test_pred)}\") # Test Precsion\n",
        "print(f\"Test Recall: {recall_score(y_test, y_voting_test_pred)}\") # Test Recall\n",
        "confusion_matrix(y_test, y_voting_test_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThEIGwjlvaxw",
        "outputId": "60935eb3-bfcc-479d-f79f-e989415d1162"
      },
      "outputs": [],
      "source": [
        "y_test_proba = model_pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "best_recall_threshold = 0.175\n",
        "y_test_pred = (y_test_proba >= best_recall_threshold).astype(int)\n",
        "\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "test_precision = precision_score(y_test, y_test_pred)\n",
        "test_recall = recall_score(y_test, y_test_pred)\n",
        "test_conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall: {test_recall:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(test_conf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkq3GjXbwpIL"
      },
      "source": [
        "# save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEXSSZ4gwrJg",
        "outputId": "4aed1b05-00aa-48b6-c321-7a538167dbbf"
      },
      "outputs": [],
      "source": [
        "joblib.dump(model_pipeline, 'model_pipeline.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(model_pipeline, 'model_pipeline.pkl', compress=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"best_threshold.json\", \"w\") as f:\n",
        "    json.dump({\"best_threshold\": best_recall_threshold}, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Thanks being her till the end of this presentation​\n",
        "\n",
        "# Check our linkedIN: https://www.linkedin.com/in/mostafa-saad-7a6b8a30b/​\n",
        "\n",
        "# Check my github: https://github.com/mostafa-s-mostafa/Final-project​\n",
        "\n",
        "# Check the depoyment: ​https://mostafa-final-project-deployment.streamlit.app/"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "machine_learning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
